{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AbhiShek\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "C:\\Users\\AbhiShek\\Anaconda3\\lib\\site-packages\\sklearn\\learning_curve.py:22: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the functions are moved. This module will be removed in 0.20\n",
      "  DeprecationWarning)\n",
      "C:\\Users\\AbhiShek\\Anaconda3\\lib\\site-packages\\sklearn\\ensemble\\weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n",
      "C:\\Users\\AbhiShek\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1209: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# ============================== loading libraries ===========================================\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import cross_validation\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.datasets import *\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import classification_report\n",
    "from prettytable import PrettyTable\n",
    "import random\n",
    "from scipy.stats import uniform\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.learning_curve import validation_curve\n",
    "from sklearn.metrics import fbeta_score, make_scorer\n",
    "from sklearn.metrics import precision_score, recall_score,roc_auc_score\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import joblib\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "#import nltk\n",
    "#nltk.download('stopwords')\n",
    "\n",
    "import re\n",
    "# Tutorial about Python regular expressions: https://pymotw.com/2/re/\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "#from gensim.models import KeyedVectors\n",
    "#model = KeyedVectors.load_word2vec_format(‘GoogleNews-vectors-negative300.bin.gz’,binary=True)\n",
    "\n",
    "#import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "\n",
    "# ============================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading preprocessed data on 100K data sets and bifurcated according to TimeStamp\n",
    "fileObject = open(\"./train_to_file2.pkl\",'rb') # we open the file for reading \n",
    "X_train = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "fileObject = open(\"./x_test_to_file2.pkl\",'rb') # we open the file for reading \n",
    "X_test = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "fileObject = open(\"./y_train_to_file2.pkl\",'rb') # we open the file for reading \n",
    "y_train = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "fileObject = open(\"./y_test_to_file2.pkl\",'rb') # we open the file for reading \n",
    "y_test = pickle.load(fileObject) # load the object from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the type of count vectorizer  <class 'scipy.sparse.csr.csr_matrix'>\n",
      "the number of unique words  39675\n",
      "(42000, 39675)\n",
      "(18000, 39675)\n",
      "(18000,)\n",
      "(42000,)\n"
     ]
    }
   ],
   "source": [
    "#Appling BoW to fit and transform\n",
    "count_vect =  CountVectorizer()\n",
    "bow_nstd = count_vect.fit(X_train[:,9])\n",
    "train_bow_nstd = count_vect.transform(X_train[:,9])\n",
    "test_bow_nstd = count_vect.transform(X_test[:,9]) \n",
    "\n",
    "print(\"the type of count vectorizer \",type(train_bow_nstd))\n",
    "print(\"the number of unique words \", test_bow_nstd.get_shape()[1])\n",
    "\n",
    "print(train_bow_nstd.shape)\n",
    "print(test_bow_nstd.shape)\n",
    "print(y_test.shape)\n",
    "print(y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AbhiShek\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\AbhiShek\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n",
      "C:\\Users\\AbhiShek\\Anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:475: DataConversionWarning: Data with input dtype int64 was converted to float64 by StandardScaler.\n",
      "  warnings.warn(msg, DataConversionWarning)\n"
     ]
    }
   ],
   "source": [
    "# Colum Standardization of the BoW non-standard vector\n",
    "std_scal = StandardScaler(with_mean=False)\n",
    "std_scal.fit(train_bow_nstd)\n",
    "train_bow = std_scal.transform(train_bow_nstd)\n",
    "test_bow = std_scal.transform(test_bow_nstd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ballgames', 'ballistic', 'ballon', 'balloon', 'balloons', 'ballotin', 'ballotins', 'ballpark', 'balls', 'balm', 'balmex', 'baloney', 'balsalmic', 'balsamic', 'balsamico', 'balsamics', 'baltasar', 'baltimore', 'baluchi', 'bam', 'bamberg', 'bambi', 'bamboo', 'bamboos', 'bamboozled', 'bamilton', 'bamm', 'bammer', 'ban', 'banana', 'bananamon', 'bananas', 'bananna', 'banannas', 'bancha', 'band', 'bandages', 'banded', 'bandera', 'bandini', 'bandit', 'bands', 'bane', 'baned', 'bang', 'banged', 'banger', 'bangers', 'banging', 'bangkok', 'bangladesh', 'bangled', 'bangok', 'bangor', 'bangs', 'banh', 'banish', 'banishing', 'banjo', 'bank', 'banking', 'bankrupt', 'banks', 'bannana', 'banned', 'banner', 'banning', 'banquet', 'banquets', 'bans', 'banshee', 'bao', 'baquettes', 'bar', 'barb']\n"
     ]
    }
   ],
   "source": [
    "print(count_vect.get_feature_names()[4250:4325])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "Best score:  0.9581934619956152\n",
      "0.9533196608405523\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_l1.pkl']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using GridSearchCV with L1 Regularizer\n",
    "tuned_parameters = [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4]}]\n",
    "model_l1 = GridSearchCV(LogisticRegression(penalty='l1'), tuned_parameters, scoring = 'f1', cv=5)\n",
    "model_l1.fit(train_bow, y_train)\n",
    "\n",
    "GS_OPTIMAL_clf_l1 = model_l1.best_estimator_\n",
    "print(GS_OPTIMAL_clf_l1)\n",
    "best_score_model_l1 = model_l1.best_score_\n",
    "print(\"\\nBest score: \",best_score_model_l1)\n",
    "test_score_l1 = model_l1.score(test_bow, y_test)\n",
    "print(test_score_l1)\n",
    "\n",
    "#Writing data\n",
    "fileObject = open(\"./GS_OPTIMAL_clf_l1.pkl\",'wb')\n",
    "pickle.dump(GS_OPTIMAL_clf_l1,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "# open the file for writing an array to fileto be save on disk from X_test data\n",
    "fileObject = open(\"./best_score_model_l1.pkl\",'wb')\n",
    "pickle.dump(best_score_model_l1,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "# open the file for writing an array to fileto be save on disk from X_test data\n",
    "fileObject = open(\"./test_score_l1.pkl\",'wb')\n",
    "pickle.dump(test_score_l1,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "joblib.dump(model_l1,\"model_l1.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.9581934619956152\n",
      "0.9533196608405523\n",
      "GridSearchCV(cv=5, error_score='raise',\n",
      "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid=[{'C': [0.0001, 0.01, 1, 100, 10000]}],\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring='f1', verbose=0)\n"
     ]
    }
   ],
   "source": [
    "model_l1 = joblib.load(\"model_l1.pkl\")\n",
    "\n",
    "fileObject = open(\"./GS_OPTIMAL_clf_l1.pkl\",'rb') # we open the file for reading \n",
    "GS_OPTIMAL_clf_l1 = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "fileObject = open(\"./best_score_model_l1.pkl\",'rb') # we open the file for reading \n",
    "best_score_model_l1 = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "fileObject = open(\"./test_score_l1.pkl\",'rb') # we open the file for reading \n",
    "test_score_l1 = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "print(GS_OPTIMAL_clf_l1)\n",
    "print(best_score_model_l1)\n",
    "print(test_score_l1)\n",
    "print(model_l1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for alphas:\n",
      "[mean: 0.94177, std: 0.00003, params: {'C': 0.0001}, mean: 0.95819, std: 0.00146, params: {'C': 0.01}, mean: 0.95381, std: 0.00061, params: {'C': 1}, mean: 0.94687, std: 0.00182, params: {'C': 100}, mean: 0.93865, std: 0.00101, params: {'C': 10000}]\n",
      "Best estimator:\n",
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Best score:\n",
      "0.9581934619956152\n",
      "Best parameters:\n",
      "{'C': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AbhiShek\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "    print(\"Scores for alphas:\")\n",
    "    print(model_l1.grid_scores_)\n",
    "    print(\"Best estimator:\")\n",
    "    print(model_l1.best_estimator_)\n",
    "    print(\"Best score:\")\n",
    "    print(model_l1.best_score_)\n",
    "    print(\"Best parameters:\")\n",
    "    print(model_l1.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "Best score:  0.9578844747026857\n",
      "0.9519191919191918\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_l2.pkl']"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using GridSearchCV with L2 Regularizer\n",
    "tuned_parameters = [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4]}]\n",
    "model_l2 = GridSearchCV(LogisticRegression(penalty='l2'), tuned_parameters, scoring = 'f1', cv=5)\n",
    "model_l2.fit(train_bow, y_train)\n",
    "\n",
    "GS_OPTIMAL_clf_l2 = model_l2.best_estimator_\n",
    "print(GS_OPTIMAL_clf_l2)\n",
    "\n",
    "best_score_l2 = model_l2.best_score_\n",
    "print(\"\\nBest score: \",best_score_l2)\n",
    "test_score_l2 = model_l2.score(test_bow, y_test)\n",
    "print(test_score_l2)\n",
    "\n",
    "\n",
    "#Writing data\n",
    "fileObject = open(\"./GS_OPTIMAL_clf_l2.pkl\",'wb')\n",
    "pickle.dump(GS_OPTIMAL_clf_l2,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "# open the file for writing an array to fileto be save on disk from X_test data\n",
    "fileObject = open(\"./best_score_l2.pkl\",'wb')\n",
    "pickle.dump(best_score_l2,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "# open the file for writing an array to fileto be save on disk from X_test data\n",
    "fileObject = open(\"./test_score_l2.pkl\",'wb')\n",
    "pickle.dump(test_score_l2,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "joblib.dump(model_l2,\"model_l2.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.9578844747026857\n",
      "0.9519191919191918\n",
      "GridSearchCV(cv=5, error_score='raise',\n",
      "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid=[{'C': [0.0001, 0.01, 1, 100, 10000]}],\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring='f1', verbose=0)\n"
     ]
    }
   ],
   "source": [
    "model_l2 = joblib.load(\"model_l2.pkl\")\n",
    "\n",
    "fileObject = open(\"./GS_OPTIMAL_clf_l2.pkl\",'rb') # we open the file for reading \n",
    "GS_OPTIMAL_clf_l2 = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "fileObject = open(\"./best_score_l2.pkl\",'rb') # we open the file for reading \n",
    "best_score_l2 = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "fileObject = open(\"./test_score_l2.pkl\",'rb') # we open the file for reading \n",
    "test_score_l2 = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "print(GS_OPTIMAL_clf_l2)\n",
    "print(best_score_l2)\n",
    "print(test_score_l2)\n",
    "print(model_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2258 [[-0.01912245  0.          0.         ...  0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# More Sparsity (Fewer elements of W* being non-zero) by increasing Lambda (decreasing C) \n",
    "clf_c1 = LogisticRegression(C=0.01, penalty='l1');\n",
    "clf_c1.fit(train_bow, y_train);\n",
    "w = clf_c1.coef_\n",
    "print(np.count_nonzero(w), w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6673\n"
     ]
    }
   ],
   "source": [
    "# More Sparsity (Fewer elements of W* being non-zero) by increasing Lambda (decreasing C) \n",
    "clf_c2 = LogisticRegression(C=0.1, penalty='l1');\n",
    "clf_c2.fit(train_bow, y_train);\n",
    "w = clf_c2.coef_\n",
    "print(np.count_nonzero(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7868\n"
     ]
    }
   ],
   "source": [
    "# More Sparsity (Fewer elements of W* being non-zero) by decreasing Lambda (increasing C) \n",
    "clf_c3 = LogisticRegression(C=1, penalty='l1');\n",
    "clf_c3.fit(train_bow, y_train);\n",
    "w = clf_c3.coef_\n",
    "print(np.count_nonzero(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8288\n"
     ]
    }
   ],
   "source": [
    "# More Sparsity (Fewer elements of W* being non-zero) by increasing Lambda (decreasing C) \n",
    "clf_c4 = LogisticRegression(C=10, penalty='l1');\n",
    "clf_c4.fit(train_bow, y_train);\n",
    "w = clf_c4.coef_\n",
    "print(np.count_nonzero(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13114\n",
      "(1, 39675)\n"
     ]
    }
   ],
   "source": [
    "# More Sparsity (Fewer elements of W* being non-zero) by increasing Lambda (decreasing C) \n",
    "clf_c5 = LogisticRegression(C=100, penalty='l1');\n",
    "clf_c5.fit(train_bow, y_train);\n",
    "w = clf_c5.coef_\n",
    "print(np.count_nonzero(w))\n",
    "print(np.shape(w))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:  [[-1.91188629e-02  1.00000000e-07  1.00000000e-07 ...  1.00000000e-07\n",
      "   1.00000000e-07  1.00000000e-07]]\n",
      "w_1:  [[-1.9107843e-02  1.0000000e-07  1.0000000e-07 ...  1.0000000e-07\n",
      "   1.0000000e-07  1.0000000e-07]]\n",
      "per_array:  [[0.05763893 0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#perturbation testing\n",
    "index = []\n",
    "\n",
    "clf_c1.fit(train_bow, y_train)\n",
    "w=clf_c1.coef_+0.0000001\n",
    "#print(np.shape(w))\n",
    "print(\"w: \",w)\n",
    "\n",
    "train_bow.data += 0.001\n",
    "clf_c1.fit(train_bow, y_train)\n",
    "w_1=clf_c1.coef_+0.0000001\n",
    "#print(np.shape(w_1))\n",
    "print(\"w_1: \",w_1)\n",
    "\n",
    "per_array= np.abs((w-w_1)/w)*100\n",
    "print(\"per_array: \",per_array)\n",
    "#print(np.shape(per_array))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights =  0.0\n",
      "Weights =  0.0\n",
      "Weights =  0.0\n",
      "Weights =  0.0\n",
      "Weights =  0.0\n",
      "Weights =  0.0\n",
      "Weights =  0.0\n",
      "Weights =  0.0\n",
      "Weights =  0.0\n",
      "Weights =  0.0\n",
      "Weights =  26138234.36439968\n",
      "**************************\n"
     ]
    }
   ],
   "source": [
    "#between 1st-100th percentile\n",
    "for i in range(0,101,10):\n",
    "    Weights = np.percentile(per_array, i)\n",
    "    print(\"Weights = \",Weights)\n",
    "print(\"**************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights =  0.0\n",
      "Weights =  0.0\n",
      "Weights =  0.0\n",
      "Weights =  0.0\n",
      "Weights =  0.0\n",
      "Weights =  0.021549709583148013\n",
      "Weights =  0.0640694482884901\n",
      "Weights =  0.18785448795017512\n",
      "Weights =  2.1792054013884457\n",
      "Weights =  88.57803957725572\n",
      "Weights =  26138234.36439968\n",
      "**************************\n"
     ]
    }
   ],
   "source": [
    "#between 90th-100th percentile\n",
    "for i in range(90,101,1):\n",
    "    Weights = np.percentile(per_array, i)\n",
    "    print(\"Weights = \",Weights)\n",
    "print(\"**************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights =  88.57803957725572\n",
      "Weights =  95.44179855289318\n",
      "Weights =  99.65272173460104\n",
      "Weights =  100.01149984024542\n",
      "Weights =  127.35578706999286\n",
      "Weights =  221.5114438404176\n",
      "Weights =  429.08519617188904\n",
      "Weights =  1049.2464256830942\n",
      "Weights =  7546.465456957729\n",
      "Weights =  322191.5821214678\n",
      "Weights =  26138234.36433728\n",
      "**************************\n"
     ]
    }
   ],
   "source": [
    "#between 99th-100th percentile\n",
    "k=99\n",
    "for i in range(1,12,1):\n",
    "    Weights_3 = np.percentile(per_array, k)\n",
    "    print(\"Weights = \",Weights_3)   \n",
    "    k+=0.1\n",
    "print(\"**************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights =  221.5114438404213\n",
      "Weights =  429.08519617189756\n",
      "**************************\n",
      "[221.5114438404213, 429.08519617189756]\n",
      "Threshold value =  207.57375233147627\n"
     ]
    }
   ],
   "source": [
    "#between 99.5th - 99.6th percentile\n",
    "Weight_chng = []\n",
    "#Weight_chng = np.asarray(Weights_4)\n",
    "k=99.5\n",
    "for i in range(1,3):\n",
    "    Weights_3 = np.percentile(per_array, k)\n",
    "    print(\"Weights = \",Weights_3) \n",
    "    Weight_chng.append(Weights_3)\n",
    "    #Weight_chng = Weights_3\n",
    "    k+=0.1\n",
    "print(\"**************************\")\n",
    "\n",
    "print(Weight_chng)\n",
    "thrsh = np.abs(Weight_chng[0] - Weight_chng[1]) #taking threshold value for weight change\n",
    "print(\"Threshold value = \",thrsh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshhold taken for abrupt changes =  207.57375233147627\n",
      "Number of features with abrupt changes =  203\n",
      "\n",
      "\n",
      "Feature Names:  0451155505\n",
      "Feature Names:  10yrs\n",
      "Feature Names:  117\n",
      "Feature Names:  1230\n",
      "Feature Names:  239\n",
      "Feature Names:  23lb\n",
      "Feature Names:  30ct\n",
      "Feature Names:  30oz\n",
      "Feature Names:  348\n",
      "Feature Names:  407\n",
      "Feature Names:  4ish\n",
      "Feature Names:  6402\n",
      "Feature Names:  80gb\n",
      "Feature Names:  8545\n",
      "Feature Names:  ablaze\n",
      "Feature Names:  addams\n",
      "Feature Names:  addicitve\n",
      "Feature Names:  adele\n",
      "Feature Names:  adovada\n",
      "Feature Names:  advertizement\n",
      "Feature Names:  algorithms\n",
      "Feature Names:  alleries\n",
      "Feature Names:  allsorts\n",
      "Feature Names:  anon_2003\n",
      "Feature Names:  anyrhinf\n",
      "Feature Names:  areagarden\n",
      "Feature Names:  arroyo\n",
      "Feature Names:  austrians\n",
      "Feature Names:  b0002zbkzw\n",
      "Feature Names:  b000cqbzoc\n",
      "Feature Names:  b000fph1t8\n",
      "Feature Names:  b000g6o2qg\n",
      "Feature Names:  b000jz5cqs\n",
      "Feature Names:  b000nlsp1c\n",
      "Feature Names:  b000nmi5i4\n",
      "Feature Names:  b000pwyjp0\n",
      "Feature Names:  b0014dwh2q\n",
      "Feature Names:  b0014dzqfq\n",
      "Feature Names:  b0014dzqga\n",
      "Feature Names:  b001eua0v4\n",
      "Feature Names:  bendings\n",
      "Feature Names:  bioflavanoid\n",
      "Feature Names:  blocker\n",
      "Feature Names:  bluebirds\n",
      "Feature Names:  boscoworld\n",
      "Feature Names:  breathalyser\n",
      "Feature Names:  brm\n",
      "Feature Names:  buchanan\n",
      "Feature Names:  burrs\n",
      "Feature Names:  catalytic\n",
      "Feature Names:  cayotes\n",
      "Feature Names:  centrist\n",
      "Feature Names:  chiou\n",
      "Feature Names:  chocolite\n",
      "Feature Names:  clasico\n",
      "Feature Names:  classick\n",
      "Feature Names:  clod\n",
      "Feature Names:  clunk\n",
      "Feature Names:  colossal\n",
      "Feature Names:  comatose\n",
      "Feature Names:  cordboard\n",
      "Feature Names:  crapy\n",
      "Feature Names:  craven\n",
      "Feature Names:  cypriot\n",
      "Feature Names:  darwish\n",
      "Feature Names:  deleats\n",
      "Feature Names:  delice\n",
      "Feature Names:  derogatory\n",
      "Feature Names:  diahorrea\n",
      "Feature Names:  diggers\n",
      "Feature Names:  dimestore\n",
      "Feature Names:  din\n",
      "Feature Names:  disable\n",
      "Feature Names:  disparaging\n",
      "Feature Names:  disrespectful\n",
      "Feature Names:  dissappointing\n",
      "Feature Names:  distributer\n",
      "Feature Names:  distrustful\n",
      "Feature Names:  dom\n",
      "Feature Names:  dormant\n",
      "Feature Names:  earthworm\n",
      "Feature Names:  entioned\n",
      "Feature Names:  explanantion\n",
      "Feature Names:  fathi\n",
      "Feature Names:  flippin\n",
      "Feature Names:  fruitish\n",
      "Feature Names:  fsm\n",
      "Feature Names:  fuzhou\n",
      "Feature Names:  geletin\n",
      "Feature Names:  gid\n",
      "Feature Names:  gobino\n",
      "Feature Names:  grandaughters\n",
      "Feature Names:  grandious\n",
      "Feature Names:  halloumi\n",
      "Feature Names:  hamdan\n",
      "Feature Names:  hardish\n",
      "Feature Names:  hmmmmmm\n",
      "Feature Names:  hustle\n",
      "Feature Names:  hydrogonated\n",
      "Feature Names:  insulating\n",
      "Feature Names:  involuntarily\n",
      "Feature Names:  jivalime\n",
      "Feature Names:  jowl\n",
      "Feature Names:  keillor\n",
      "Feature Names:  kiddin\n",
      "Feature Names:  kohinoor\n",
      "Feature Names:  leakiing\n",
      "Feature Names:  leke\n",
      "Feature Names:  lenghtly\n",
      "Feature Names:  losers\n",
      "Feature Names:  maillard\n",
      "Feature Names:  martyrs\n",
      "Feature Names:  marye\n",
      "Feature Names:  mbayaq\n",
      "Feature Names:  meisters\n",
      "Feature Names:  miffed\n",
      "Feature Names:  milquetoast\n",
      "Feature Names:  mimalist\n",
      "Feature Names:  mohamed\n",
      "Feature Names:  molido\n",
      "Feature Names:  molts\n",
      "Feature Names:  morons\n",
      "Feature Names:  mothering\n",
      "Feature Names:  mulched\n",
      "Feature Names:  mulchy\n",
      "Feature Names:  nejm\n",
      "Feature Names:  newdsay\n",
      "Feature Names:  notifiction\n",
      "Feature Names:  nutrapoison\n",
      "Feature Names:  obviate\n",
      "Feature Names:  ohyeah\n",
      "Feature Names:  overpaid\n",
      "Feature Names:  oxidase\n",
      "Feature Names:  packers\n",
      "Feature Names:  paradoxical\n",
      "Feature Names:  pasture\n",
      "Feature Names:  pernigotti\n",
      "Feature Names:  pheremone\n",
      "Feature Names:  piazza\n",
      "Feature Names:  planett\n",
      "Feature Names:  pluribus\n",
      "Feature Names:  poppodums\n",
      "Feature Names:  pourri\n",
      "Feature Names:  putting\n",
      "Feature Names:  rationale\n",
      "Feature Names:  razmatazz\n",
      "Feature Names:  receved\n",
      "Feature Names:  recomed\n",
      "Feature Names:  regimens\n",
      "Feature Names:  relents\n",
      "Feature Names:  relooc\n",
      "Feature Names:  renewing\n",
      "Feature Names:  responder\n",
      "Feature Names:  restocked\n",
      "Feature Names:  retching\n",
      "Feature Names:  roccoco\n",
      "Feature Names:  rona\n",
      "Feature Names:  rstd\n",
      "Feature Names:  ruse\n",
      "Feature Names:  rushmore\n",
      "Feature Names:  saddend\n",
      "Feature Names:  sang\n",
      "Feature Names:  sasparilla\n",
      "Feature Names:  satellite\n",
      "Feature Names:  schade\n",
      "Feature Names:  schmo\n",
      "Feature Names:  seasame\n",
      "Feature Names:  shrinkwrap\n",
      "Feature Names:  slums\n",
      "Feature Names:  spindly\n",
      "Feature Names:  starpucky\n",
      "Feature Names:  stoli\n",
      "Feature Names:  stronggg\n",
      "Feature Names:  sucepan\n",
      "Feature Names:  surroundings\n",
      "Feature Names:  swine\n",
      "Feature Names:  tartaric\n",
      "Feature Names:  territories\n",
      "Feature Names:  tesh\n",
      "Feature Names:  thermogenesis\n",
      "Feature Names:  thugs\n",
      "Feature Names:  toledo\n",
      "Feature Names:  toothfish\n",
      "Feature Names:  toothppicks\n",
      "Feature Names:  tortureous\n",
      "Feature Names:  toxicology\n",
      "Feature Names:  tradeoffs\n",
      "Feature Names:  trenton\n",
      "Feature Names:  trudging\n",
      "Feature Names:  tuffest\n",
      "Feature Names:  undergoes\n",
      "Feature Names:  underhanded\n",
      "Feature Names:  unfamiliarity\n",
      "Feature Names:  wabbits\n",
      "Feature Names:  watchdog\n",
      "Feature Names:  watermeion\n",
      "Feature Names:  weavil\n",
      "Feature Names:  whaaaaat\n",
      "Feature Names:  wrigleys\n",
      "Feature Names:  wymans\n",
      "Feature Names:  yessiree\n",
      "Feature Names:  yoed\n",
      "Feature Names:  z3\n"
     ]
    }
   ],
   "source": [
    "Weight_chng_3 = []\n",
    "loop2 = np.shape(train_bow)\n",
    "\n",
    "for loop1 in range(0,loop2[1]):\n",
    "    Weight_chng_3[0:loop1] = np.abs((w-w_1)/w)*100\n",
    "Weight_chng_2 = np.asarray(Weight_chng_3)\n",
    "\n",
    "\n",
    "loop4 = 0\n",
    "index2 = []\n",
    "for loop3 in range(0,loop2[1]):    \n",
    "    if (Weight_chng_2[0,loop3] >= thrsh):\n",
    "        index2.append(loop3)\n",
    "        loop4 +=1\n",
    "        \n",
    "leng = len(index2)\n",
    "print(\"Threshhold taken for abrupt changes = \",thrsh)\n",
    "print(\"Number of features with abrupt changes = \",leng)\n",
    "print(\"\\n\")\n",
    "\n",
    "feature_names = count_vect.get_feature_names()\n",
    "\n",
    "for k in index2:\n",
    "     print(\"Feature Names: \",feature_names[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l1\n",
      "Best C: 0.8178089989260697\n"
     ]
    }
   ],
   "source": [
    "# Create logistic regression\n",
    "logistic = LogisticRegression()\n",
    "\n",
    "# Create regularization penalty space\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create regularization hyperparameter distribution using uniform distribution\n",
    "C = uniform(loc=0, scale=4)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "# Create randomized search 5-fold cross validation and 100 iterations\n",
    "clf_rscv = RandomizedSearchCV(logistic, hyperparameters, random_state=1, cv=5)\n",
    "\n",
    "# Fit randomized search\n",
    "best_model = clf_rscv.fit(train_bow, y_train)\n",
    "\n",
    "# View best hyperparameters\n",
    "best_penalty = best_model.best_estimator_.get_params()['penalty']\n",
    "print('Best Penalty:',best_penalty )\n",
    "best_c = best_model.best_estimator_.get_params()['C']\n",
    "print('Best C:',best_c)\n",
    "\n",
    "# Predict target vector\n",
    "predict_test = best_model.predict(test_bow)\n",
    "\n",
    "#Writing data\n",
    "fileObject = open(\"./best_penalty.pkl\",'wb')\n",
    "pickle.dump(best_penalty,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "# open the file for writing an array to fileto be save on disk from X_test data\n",
    "fileObject = open(\"./best_c.pkl\",'wb')\n",
    "pickle.dump(best_c,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "# open the file for writing an array to fileto be save on disk from X_test data\n",
    "fileObject = open(\"./predict_test.pkl\",'wb')\n",
    "pickle.dump(predict_test,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1\n",
      "0.8178089989260697\n",
      "[1 0 1 ... 1 1 1]\n"
     ]
    }
   ],
   "source": [
    "fileObject = open(\"./best_penalty.pkl\",'rb') # we open the file for reading \n",
    "best_penalty = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "fileObject = open(\"./best_c.pkl\",'rb') # we open the file for reading \n",
    "best_c = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "fileObject = open(\"./predict_test.pkl\",'rb') # we open the file for reading \n",
    "predict_test = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "print(best_penalty)\n",
    "print(best_c)\n",
    "print(predict_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: Negatives \n",
      "0 -0.38459975029538646 not\n",
      "0 -0.20005237705935414 worst\n",
      "0 -0.19454206247389794 disappointed\n",
      "0 -0.15265322646418467 horrible\n",
      "0 -0.152283957397188 terrible\n",
      "0 -0.14071948547945395 awful\n",
      "0 -0.13951639998883827 unfortunately\n",
      "0 -0.12623767309950973 bland\n",
      "0 -0.12043856922648584 bad\n",
      "0 -0.11894286920602978 disappointing\n",
      "\n",
      "\n",
      "Class 1: Positives \n",
      "1 0.6033694459260905 great\n",
      "1 0.44256606189011727 best\n",
      "1 0.3706455502789717 delicious\n",
      "1 0.27638293379623935 wonderful\n",
      "1 0.2604975791630741 good\n",
      "1 0.2543307903700292 love\n",
      "1 0.24734545974119804 perfect\n",
      "1 0.233575414916343 excellent\n",
      "1 0.2271868789106424 and\n",
      "1 0.2077492991157471 nice\n"
     ]
    }
   ],
   "source": [
    "def most_informative_feature_for_binary_classification(vectorizer, classifier, n=10):\n",
    "    class_labels = classifier.classes_\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    topn_class1 = sorted(zip(classifier.coef_[0], feature_names))[:n]\n",
    "    topn_class2 = sorted(zip(classifier.coef_[0], feature_names))[-n:]\n",
    "\n",
    "    print(\"Class 0: Negatives \")\n",
    "    for coef, feat in topn_class1:\n",
    "        print (class_labels[0], coef, feat)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"Class 1: Positives \")\n",
    "    for coef, feat in reversed(topn_class2):\n",
    "        print (class_labels[1], coef, feat)\n",
    "\n",
    "\n",
    "most_informative_feature_for_binary_classification(count_vect, clf_c1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 39675)\n",
      "(18000, 39675)\n"
     ]
    }
   ],
   "source": [
    "#tf-idf on train data\n",
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,1)) #considering only uni-gram as I was getting memory error\n",
    "train_tf_idf_nstd = tf_idf_vect.fit_transform(X_train[:,9]) #sparse matrix\n",
    "test_tfidf_nstd = tf_idf_vect.transform(X_test[:,9])\n",
    "print(train_tf_idf_nstd.shape)\n",
    "print(test_tfidf_nstd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Standardization of the tfidf non-standard vector\n",
    "std_scal = StandardScaler(with_mean=False)\n",
    "std_scal.fit(train_tf_idf_nstd)\n",
    "train_tfidf = std_scal.transform(train_tf_idf_nstd)\n",
    "test_tfidf = std_scal.transform(test_tfidf_nstd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "Best score:  0.9581934619956152\n",
      "0.9543866102630127\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_l1_tfidf.pkl']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using GridSearchCV with L1 Regularizer\n",
    "tuned_parameters = [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4]}]\n",
    "model_l1_tfidf = GridSearchCV(LogisticRegression(penalty='l1'), tuned_parameters, scoring = 'f1', cv=5)\n",
    "model_l1_tfidf.fit(train_tfidf, y_train)\n",
    "\n",
    "GS_OPTIMAL_clf_l1_tfidf = model_l1.best_estimator_\n",
    "print(GS_OPTIMAL_clf_l1_tfidf)\n",
    "best_score_model_l1_tfidf = model_l1.best_score_\n",
    "print(\"\\nBest score: \",best_score_model_l1_tfidf)\n",
    "test_score_l1_tfidf = model_l1_tfidf.score(test_tfidf, y_test)\n",
    "print(test_score_l1_tfidf)\n",
    "\n",
    "#Writing data\n",
    "fileObject = open(\"./GS_OPTIMAL_clf_l1_tfidf.pkl\",'wb')\n",
    "pickle.dump(GS_OPTIMAL_clf_l1_tfidf,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "# open the file for writing an array to fileto be save on disk from X_test data\n",
    "fileObject = open(\"./best_score_model_l1_tfidf.pkl\",'wb')\n",
    "pickle.dump(best_score_model_l1_tfidf,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "# open the file for writing an array to fileto be save on disk from X_test data\n",
    "fileObject = open(\"./test_score_l1_tfidf.pkl\",'wb')\n",
    "pickle.dump(test_score_l1_tfidf,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "joblib.dump(model_l1_tfidf,\"model_l1_tfidf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.9581934619956152\n",
      "0.9543866102630127\n",
      "GridSearchCV(cv=5, error_score='raise',\n",
      "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid=[{'C': [0.0001, 0.01, 1, 100, 10000]}],\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring='f1', verbose=0)\n"
     ]
    }
   ],
   "source": [
    "model_l1_tfidf = joblib.load(\"model_l1_tfidf.pkl\")\n",
    "\n",
    "fileObject = open(\"./GS_OPTIMAL_clf_l1_tfidf.pkl\",'rb') # we open the file for reading \n",
    "GS_OPTIMAL_clf_l1_tfidf = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "fileObject = open(\"./best_score_model_l1_tfidf.pkl\",'rb') # we open the file for reading \n",
    "best_score_model_l1_tfidf = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "fileObject = open(\"./test_score_l1_tfidf.pkl\",'rb') # we open the file for reading \n",
    "test_score_l1_tfidf = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "print(GS_OPTIMAL_clf_l1_tfidf)\n",
    "print(best_score_model_l1_tfidf)\n",
    "print(test_score_l1_tfidf)\n",
    "print(model_l1_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for alphas:\n",
      "[mean: 0.91073, std: 0.00353, params: {'C': 0.0001}, mean: 0.95892, std: 0.00090, params: {'C': 0.01}, mean: 0.95363, std: 0.00089, params: {'C': 1}, mean: 0.94321, std: 0.00090, params: {'C': 100}, mean: 0.93585, std: 0.00059, params: {'C': 10000}]\n",
      "Best estimator:\n",
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Best score:\n",
      "0.9589154256304367\n",
      "Best parameters:\n",
      "{'C': 0.01}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AbhiShek\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "    print(\"Scores for alphas:\")\n",
    "    print(model_l1_tfidf.grid_scores_)\n",
    "    print(\"Best estimator:\")\n",
    "    print(model_l1_tfidf.best_estimator_)\n",
    "    print(\"Best score:\")\n",
    "    print(model_l1_tfidf.best_score_)\n",
    "    print(\"Best parameters:\")\n",
    "    print(model_l1_tfidf.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "Best score:  0.9535812754753286\n",
      "0.9443043491796643\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_l2_tfidf.pkl']"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using GridSearchCV with L2 Regularizer\n",
    "tuned_parameters = [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4]}]\n",
    "model_l2_tfidf = GridSearchCV(LogisticRegression(penalty='l2'), tuned_parameters, scoring = 'f1', cv=5)\n",
    "model_l2_tfidf.fit(train_tfidf, y_train)\n",
    "\n",
    "GS_OPTIMAL_clf_l2_tfidf = model_l2_tfidf.best_estimator_\n",
    "print(GS_OPTIMAL_clf_l2_tfidf)\n",
    "\n",
    "best_score_l2_tfidf = model_l2_tfidf.best_score_\n",
    "print(\"\\nBest score: \",best_score_l2_tfidf)\n",
    "test_score_l2_tfidf = model_l2_tfidf.score(test_tfidf, y_test)\n",
    "print(test_score_l2_tfidf)\n",
    "\n",
    "\n",
    "#Writing data\n",
    "fileObject = open(\"./GS_OPTIMAL_clf_l2_tfidf.pkl\",'wb')\n",
    "pickle.dump(GS_OPTIMAL_clf_l2_tfidf,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "# open the file for writing an array to fileto be save on disk from X_test data\n",
    "fileObject = open(\"./best_score_l2_tfidf.pkl\",'wb')\n",
    "pickle.dump(best_score_l2_tfidf,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "# open the file for writing an array to fileto be save on disk from X_test data\n",
    "fileObject = open(\"./test_score_l2_tfidf.pkl\",'wb')\n",
    "pickle.dump(test_score_l2_tfidf,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "joblib.dump(model_l2_tfidf,\"model_l2_tfidf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.9535812754753286\n",
      "0.9443043491796643\n"
     ]
    }
   ],
   "source": [
    "model_l2_tfidf = joblib.load(\"model_l2_tfidf.pkl\")\n",
    "\n",
    "fileObject = open(\"./GS_OPTIMAL_clf_l2_tfidf.pkl\",'rb') # we open the file for reading \n",
    "GS_OPTIMAL_clf_l2_tfidf = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "fileObject = open(\"./best_score_l2_tfidf.pkl\",'rb') # we open the file for reading \n",
    "best_score_l2_tfidf = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "fileObject = open(\"./test_score_l2_tfidf.pkl\",'rb') # we open the file for reading \n",
    "test_score_l2_tfidf = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "print(GS_OPTIMAL_clf_l2_tfidf)\n",
    "print(best_score_l2_tfidf)\n",
    "print(test_score_l2_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2579 [[-0.02152811  0.          0.         ...  0.          0.\n",
      "   0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# More Sparsity (Fewer elements of W* being non-zero) by increasing Lambda (decreasing C) \n",
    "clf_c1_tfidf = LogisticRegression(C=0.01, penalty='l1');\n",
    "clf_c1_tfidf.fit(train_tfidf, y_train);\n",
    "w_tfidf = clf_c1_tfidf.coef_\n",
    "print(np.count_nonzero(w_tfidf), w_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7812\n"
     ]
    }
   ],
   "source": [
    "# More Sparsity (Fewer elements of W* being non-zero) by increasing Lambda (decreasing C) \n",
    "clf_c2_tfidf = LogisticRegression(C=0.1, penalty='l1');\n",
    "clf_c2_tfidf.fit(train_tfidf, y_train);\n",
    "w_tfidf = clf_c2_tfidf.coef_\n",
    "print(np.count_nonzero(w_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8892\n"
     ]
    }
   ],
   "source": [
    "# More Sparsity (Fewer elements of W* being non-zero) by decreasing Lambda (increasing C) \n",
    "clf_c3_tfidf = LogisticRegression(C=1, penalty='l1');\n",
    "clf_c3_tfidf.fit(train_tfidf, y_train);\n",
    "w_tfidf = clf_c3_tfidf.coef_\n",
    "print(np.count_nonzero(w_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9433\n"
     ]
    }
   ],
   "source": [
    "# More Sparsity (Fewer elements of W* being non-zero) by increasing Lambda (decreasing C) \n",
    "clf_c4_tfidf = LogisticRegression(C=10, penalty='l1');\n",
    "clf_c4_tfidf.fit(train_tfidf, y_train);\n",
    "w_tfidf = clf_c4_tfidf.coef_\n",
    "print(np.count_nonzero(w_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14786\n",
      "(1, 39675)\n"
     ]
    }
   ],
   "source": [
    "# More Sparsity (Fewer elements of W* being non-zero) by increasing Lambda (decreasing C) \n",
    "clf_c5_tfidf = LogisticRegression(C=100, penalty='l1');\n",
    "clf_c5_tfidf.fit(train_tfidf, y_train);\n",
    "w_tfidf = clf_c5_tfidf.coef_\n",
    "print(np.count_nonzero(w_tfidf))\n",
    "print(np.shape(w_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:  [[-2.15256299e-02  1.00000000e-07  1.00000000e-07 ...  1.00000000e-07\n",
      "   1.00000000e-07  1.00000000e-07]]\n",
      "w_1:  [[-2.15360595e-02  1.00000000e-07  1.00000000e-07 ...  1.00000000e-07\n",
      "   1.00000000e-07  1.00000000e-07]]\n",
      "per_array:  [[0.04845198 0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "#perturbation testing\n",
    "index = []\n",
    "\n",
    "clf_c1_tfidf.fit(train_tfidf, y_train)\n",
    "w_tfidf=clf_c1_tfidf.coef_+0.0000001\n",
    "#print(np.shape(w_tfidf))\n",
    "print(\"w: \",w_tfidf)\n",
    "\n",
    "train_tfidf.data += 0.001\n",
    "clf_c1_tfidf.fit(train_tfidf, y_train)\n",
    "w_1_tfidf=clf_c1_tfidf.coef_+0.0000001\n",
    "#print(np.shape(w_1_tfidf))\n",
    "print(\"w_1: \",w_1_tfidf)\n",
    "\n",
    "per_array_tfidf= np.abs((w_tfidf-w_1_tfidf)/w_tfidf)*100\n",
    "print(\"per_array: \",per_array_tfidf)\n",
    "#print(np.shape(per_array_tfidf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights =  0.0\n",
      "Weights =  0.0\n",
      "Weights =  0.0\n",
      "Weights =  0.0\n",
      "Weights =  0.0\n",
      "Weights =  0.0\n",
      "Weights =  0.0\n",
      "Weights =  0.0\n",
      "Weights =  0.0\n",
      "Weights =  0.0\n",
      "Weights =  15248600.020817772\n",
      "**************************\n"
     ]
    }
   ],
   "source": [
    "#between 1st-100th percentile\n",
    "for i in range(0,101,10):\n",
    "    Weights_tfidf = np.percentile(per_array_tfidf, i)\n",
    "    print(\"Weights = \",Weights_tfidf)\n",
    "print(\"**************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights =  0.0\n",
      "Weights =  0.0\n",
      "Weights =  0.0\n",
      "Weights =  0.0\n",
      "Weights =  0.011594057239780128\n",
      "Weights =  0.03282140473185597\n",
      "Weights =  0.07021305209216433\n",
      "Weights =  0.1742312555254241\n",
      "Weights =  4.852635580005572\n",
      "Weights =  98.20156920398308\n",
      "Weights =  15248600.020817772\n",
      "**************************\n"
     ]
    }
   ],
   "source": [
    "#between 90th-100th percentile\n",
    "for i in range(90,101,1):\n",
    "    Weights_tfidf = np.percentile(per_array_tfidf, i)\n",
    "    print(\"Weights = \",Weights_tfidf)\n",
    "print(\"**************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights =  98.20156920398308\n",
      "Weights =  99.84137589278305\n",
      "Weights =  101.4841646890115\n",
      "Weights =  184.29799787353645\n",
      "Weights =  399.6296222604461\n",
      "Weights =  912.0257726016774\n",
      "Weights =  3532.9671239793374\n",
      "Weights =  11218.159084083469\n",
      "Weights =  89352.30241447946\n",
      "Weights =  1304188.0753517554\n",
      "Weights =  15248600.020748941\n",
      "**************************\n"
     ]
    }
   ],
   "source": [
    "#between 99th-100th percentile\n",
    "k=99\n",
    "for i in range(1,12,1):\n",
    "    Weights_3 = np.percentile(per_array_tfidf, k)\n",
    "    print(\"Weights = \",Weights_3)   \n",
    "    k+=0.1\n",
    "print(\"**************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights =  912.0257726017675\n",
      "Weights =  3532.967123980692\n",
      "**************************\n",
      "[912.0257726017675, 3532.967123980692]\n",
      "Threshold=  2620.9413513789245\n"
     ]
    }
   ],
   "source": [
    "#between 99.5th - 99.6th percentile\n",
    "Weight_chng = []\n",
    "#Weight_chng = np.asarray(Weights_4)\n",
    "k=99.5\n",
    "for i in range(1,3):\n",
    "    Weights_3 = np.percentile(per_array_tfidf, k)\n",
    "    print(\"Weights = \",Weights_3) \n",
    "    Weight_chng.append(Weights_3)\n",
    "    #Weight_chng = Weights_3\n",
    "    k+=0.1\n",
    "print(\"**************************\")\n",
    "\n",
    "print(Weight_chng)\n",
    "thrsh_tfidf = np.abs(Weight_chng[0] - Weight_chng[1]) #taking threshold value for weight change\n",
    "print(\"Threshold= \",thrsh_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Threshhold taken for abrupt changes =  2620.9413513789245\n",
      "Number of abrupt changes in features =  164\n",
      "\n",
      "\n",
      "Feature Names:  1200cal\n",
      "Feature Names:  1230\n",
      "Feature Names:  1601\n",
      "Feature Names:  1pod\n",
      "Feature Names:  2pod\n",
      "Feature Names:  39g\n",
      "Feature Names:  600x\n",
      "Feature Names:  6402\n",
      "Feature Names:  adjacent\n",
      "Feature Names:  afi\n",
      "Feature Names:  againgst\n",
      "Feature Names:  airbag\n",
      "Feature Names:  animatronic\n",
      "Feature Names:  assertion\n",
      "Feature Names:  atis\n",
      "Feature Names:  axiom\n",
      "Feature Names:  b0002zbkzw\n",
      "Feature Names:  b000a137li\n",
      "Feature Names:  b000cqbzoc\n",
      "Feature Names:  b000hqb76i\n",
      "Feature Names:  b000pwyjp0\n",
      "Feature Names:  b000yui576\n",
      "Feature Names:  b000zjouei\n",
      "Feature Names:  b001eua0v4\n",
      "Feature Names:  baffled\n",
      "Feature Names:  bakehouse\n",
      "Feature Names:  barcode\n",
      "Feature Names:  bolting\n",
      "Feature Names:  brio\n",
      "Feature Names:  cans\n",
      "Feature Names:  catalytic\n",
      "Feature Names:  chancing\n",
      "Feature Names:  chari\n",
      "Feature Names:  chd\n",
      "Feature Names:  chocolate_________premium\n",
      "Feature Names:  cis\n",
      "Feature Names:  clasico\n",
      "Feature Names:  coils\n",
      "Feature Names:  customize\n",
      "Feature Names:  dealy\n",
      "Feature Names:  decrees\n",
      "Feature Names:  desiccated\n",
      "Feature Names:  dhave\n",
      "Feature Names:  differentiator\n",
      "Feature Names:  disable\n",
      "Feature Names:  disappointted\n",
      "Feature Names:  disparaging\n",
      "Feature Names:  disrespectful\n",
      "Feature Names:  dogfoodanalysis\n",
      "Feature Names:  driking\n",
      "Feature Names:  earthworms\n",
      "Feature Names:  eeeek\n",
      "Feature Names:  embarassing\n",
      "Feature Names:  excelsa\n",
      "Feature Names:  facets\n",
      "Feature Names:  falsely\n",
      "Feature Names:  fathi\n",
      "Feature Names:  felids\n",
      "Feature Names:  freckles\n",
      "Feature Names:  fullscreen\n",
      "Feature Names:  grechka\n",
      "Feature Names:  harvestable\n",
      "Feature Names:  higher\n",
      "Feature Names:  hmmmmmm\n",
      "Feature Names:  hoana\n",
      "Feature Names:  horrifyingly\n",
      "Feature Names:  hotlix\n",
      "Feature Names:  hustle\n",
      "Feature Names:  impossibility\n",
      "Feature Names:  incredulous\n",
      "Feature Names:  industrially\n",
      "Feature Names:  infarctions\n",
      "Feature Names:  inhibitor\n",
      "Feature Names:  insinuated\n",
      "Feature Names:  investments\n",
      "Feature Names:  involuntarily\n",
      "Feature Names:  irishman\n",
      "Feature Names:  ja\n",
      "Feature Names:  jivalime\n",
      "Feature Names:  josephine\n",
      "Feature Names:  komissbrot\n",
      "Feature Names:  kuntze\n",
      "Feature Names:  lanai\n",
      "Feature Names:  laudatory\n",
      "Feature Names:  lighted\n",
      "Feature Names:  liscense\n",
      "Feature Names:  liverpool\n",
      "Feature Names:  marilyn\n",
      "Feature Names:  marye\n",
      "Feature Names:  mbayaq\n",
      "Feature Names:  mcase\n",
      "Feature Names:  mcburbia\n",
      "Feature Names:  mcgillicutty\n",
      "Feature Names:  mcneil\n",
      "Feature Names:  meknes\n",
      "Feature Names:  milker\n",
      "Feature Names:  mocha\n",
      "Feature Names:  morons\n",
      "Feature Names:  needt\n",
      "Feature Names:  notifiction\n",
      "Feature Names:  nurds\n",
      "Feature Names:  nutrapoison\n",
      "Feature Names:  observational\n",
      "Feature Names:  obviate\n",
      "Feature Names:  occupation\n",
      "Feature Names:  olfactory\n",
      "Feature Names:  oompa\n",
      "Feature Names:  orb\n",
      "Feature Names:  overpaid\n",
      "Feature Names:  parbroil\n",
      "Feature Names:  payroll\n",
      "Feature Names:  perfectionistic\n",
      "Feature Names:  pogo\n",
      "Feature Names:  positivie\n",
      "Feature Names:  pourri\n",
      "Feature Names:  prc\n",
      "Feature Names:  proffers\n",
      "Feature Names:  puchases\n",
      "Feature Names:  puches\n",
      "Feature Names:  reacting\n",
      "Feature Names:  reccoment\n",
      "Feature Names:  reforms\n",
      "Feature Names:  relayed\n",
      "Feature Names:  retaste\n",
      "Feature Names:  retasted\n",
      "Feature Names:  roches\n",
      "Feature Names:  rumsfeld\n",
      "Feature Names:  searle\n",
      "Feature Names:  sepia\n",
      "Feature Names:  shorting\n",
      "Feature Names:  sidestep\n",
      "Feature Names:  sililac\n",
      "Feature Names:  simillar\n",
      "Feature Names:  slums\n",
      "Feature Names:  snowstorm\n",
      "Feature Names:  soapbox\n",
      "Feature Names:  sprites\n",
      "Feature Names:  sticked\n",
      "Feature Names:  striped\n",
      "Feature Names:  stronggg\n",
      "Feature Names:  stufff\n",
      "Feature Names:  subtitle\n",
      "Feature Names:  suman\n",
      "Feature Names:  tens\n",
      "Feature Names:  tesh\n",
      "Feature Names:  testy\n",
      "Feature Names:  thurmond\n",
      "Feature Names:  toledo\n",
      "Feature Names:  tolerabe\n",
      "Feature Names:  toothppicks\n",
      "Feature Names:  trenton\n",
      "Feature Names:  tyring\n",
      "Feature Names:  uninventive\n",
      "Feature Names:  unrefreshing\n",
      "Feature Names:  warily\n",
      "Feature Names:  weavil\n",
      "Feature Names:  wer\n",
      "Feature Names:  westphalian\n",
      "Feature Names:  widly\n",
      "Feature Names:  wiredweird\n",
      "Feature Names:  withhold\n",
      "Feature Names:  wrung\n",
      "Feature Names:  yadayadayada\n",
      "Feature Names:  zaloga\n"
     ]
    }
   ],
   "source": [
    "Weight_chng_3 = []\n",
    "loop2 = np.shape(train_tfidf)\n",
    "\n",
    "for loop1 in range(0,loop2[1]):\n",
    "    Weight_chng_3[0:loop1] = np.abs((w_tfidf-w_1_tfidf)/w_tfidf)*100\n",
    "Weight_chng_2 = np.asarray(Weight_chng_3)\n",
    "\n",
    "\n",
    "loop4 = 0\n",
    "index2 = []\n",
    "for loop3 in range(0,loop2[1]):    \n",
    "    if (Weight_chng_2[0,loop3] >= thrsh_tfidf):\n",
    "        index2.append(loop3)\n",
    "        loop4 +=1\n",
    "        \n",
    "leng = len(index2)\n",
    "print(\"Threshhold taken for abrupt changes = \",thrsh_tfidf)\n",
    "print(\"Number of abrupt changes in features = \",leng)\n",
    "print(\"\\n\")\n",
    "\n",
    "feature_names_tfidf = tf_idf_vect.get_feature_names()\n",
    "\n",
    "for k in index2:\n",
    "     print(\"Feature Names: \",feature_names_tfidf[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l1\n",
      "Best C: 0.8178089989260697\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['clf_rscv_tfidf.pkl']"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create logistic regression\n",
    "logistic_tfidf = LogisticRegression()\n",
    "\n",
    "# Create regularization penalty space\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create regularization hyperparameter distribution using uniform distribution\n",
    "C = uniform(loc=0, scale=4)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "# Create randomized search 5-fold cross validation and 100 iterations\n",
    "clf_rscv_tfidf = RandomizedSearchCV(logistic_tfidf, hyperparameters, random_state=1, cv=5)\n",
    "\n",
    "# Fit randomized search\n",
    "best_model_tfidf = clf_rscv_tfidf.fit(train_tfidf, y_train)\n",
    "\n",
    "# View best hyperparameters\n",
    "best_penalty_tfidf = best_model_tfidf.best_estimator_.get_params()['penalty']\n",
    "print('Best Penalty:',best_penalty_tfidf )\n",
    "best_c_tfidf = best_model_tfidf.best_estimator_.get_params()['C']\n",
    "print('Best C:',best_c_tfidf)\n",
    "\n",
    "# Predict target vector\n",
    "predict_test_tfidf = best_model_tfidf.predict(test_tfidf)\n",
    "\n",
    "#Writing data\n",
    "fileObject = open(\"./best_penalty_tfidf.pkl\",'wb')\n",
    "pickle.dump(best_penalty_tfidf,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "# open the file for writing an array to fileto be save on disk from X_test data\n",
    "fileObject = open(\"./best_c_tfidf.pkl\",'wb')\n",
    "pickle.dump(best_c_tfidf,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "# open the file for writing an array to fileto be save on disk from X_test data\n",
    "fileObject = open(\"./predict_test_tfidf.pkl\",'wb')\n",
    "pickle.dump(predict_test_tfidf,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "joblib.dump(clf_rscv_tfidf,\"clf_rscv_tfidf.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1\n",
      "0.8178089989260697\n",
      "[1 1 1 ... 1 1 1]\n",
      "RandomizedSearchCV(cv=5, error_score='raise',\n",
      "          estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
      "          param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000265052F1C88>, 'penalty': ['l1', 'l2']},\n",
      "          pre_dispatch='2*n_jobs', random_state=1, refit=True,\n",
      "          return_train_score='warn', scoring=None, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "clf_rscv_tfidf = joblib.load(\"clf_rscv_tfidf.pkl\")\n",
    "\n",
    "fileObject = open(\"./best_penalty_tfidf.pkl\",'rb') # we open the file for reading \n",
    "best_penalty_tfidf = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "fileObject = open(\"./best_c_tfidf.pkl\",'rb') # we open the file for reading \n",
    "best_c_tfidf = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "fileObject = open(\"./predict_test_tfidf.pkl\",'rb') # we open the file for reading \n",
    "predict_test_tfidf = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "print(best_penalty_tfidf)\n",
    "print(best_c_tfidf)\n",
    "print(predict_test_tfidf)\n",
    "print(clf_rscv_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class 0: Negatives \n",
      "0 -0.3315682303599515 not\n",
      "0 -0.1945346986016476 worst\n",
      "0 -0.1698186644362145 disappointed\n",
      "0 -0.14349274391074407 terrible\n",
      "0 -0.1393662466434362 awful\n",
      "0 -0.13609875601554092 horrible\n",
      "0 -0.12209055088035092 bland\n",
      "0 -0.1158811810118024 unfortunately\n",
      "0 -0.11559974001641002 disappointing\n",
      "0 -0.11053618714782869 didn\n",
      "\n",
      "\n",
      "Class 1: Positives \n",
      "1 0.6262720880595144 great\n",
      "1 0.47801893243293403 best\n",
      "1 0.34020487284389883 delicious\n",
      "1 0.2875742262024318 love\n",
      "1 0.2677890429058033 good\n",
      "1 0.2542115453687983 wonderful\n",
      "1 0.24881977881035244 perfect\n",
      "1 0.22087164709341847 excellent\n",
      "1 0.2135477925493301 and\n",
      "1 0.20866968011684606 nice\n"
     ]
    }
   ],
   "source": [
    "def most_informative_feature_for_binary_classification(vectorizer, classifier, n=10):\n",
    "    class_labels = classifier.classes_\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "    topn_class1 = sorted(zip(classifier.coef_[0], feature_names))[:n]\n",
    "    topn_class2 = sorted(zip(classifier.coef_[0], feature_names))[-n:]\n",
    "\n",
    "    print(\"Class 0: Negatives \")\n",
    "    for coef, feat in topn_class1:\n",
    "        print (class_labels[0], coef, feat)\n",
    "\n",
    "    print(\"\\n\")\n",
    "    print(\"Class 1: Positives \")\n",
    "    for coef, feat in reversed(topn_class2):\n",
    "        print (class_labels[1], coef, feat)\n",
    "\n",
    "\n",
    "most_informative_feature_for_binary_classification(tf_idf_vect, clf_c1_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avg W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileObject = open(\"./final_to_file2.pkl\",'rb') # we open the file for reading \n",
    "final = pickle.load(fileObject) # load the object from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "witti littl book make son laugh loud recit car drive along alway sing refrain hes learn whale india droop love new word book introduc silli classic book will bet son still abl recit memori colleg\n",
      "*****************************************************************\n",
      "['witti', 'littl', 'book', 'make', 'son', 'laugh', 'loud', 'recit', 'car', 'drive', 'along', 'alway', 'sing', 'refrain', 'hes', 'learn', 'whale', 'india', 'droop', 'love', 'new', 'word', 'book', 'introduc', 'silli', 'classic', 'book', 'will', 'bet', 'son', 'still', 'abl', 'recit', 'memori', 'colleg']\n"
     ]
    }
   ],
   "source": [
    "#w2v\n",
    "# Train your own Word2Vec model using your own text corpus\n",
    "i=0\n",
    "list_of_sent=[]\n",
    "for sent in final['CleanedText'].values:\n",
    "    list_of_sent.append(sent.split())\n",
    "    \n",
    "print(type(list_of_sent))\n",
    "print(final['CleanedText'].values[0])\n",
    "print(\"*****************************************************************\")\n",
    "print(list_of_sent[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model=Word2Vec(list_of_sent,min_count=5,size=50, workers=4)\n",
    "w2v_words = list(w2v_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "# average Word2Vec\n",
    "# compute average word2vec for each review.\n",
    "sent_vectors = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sent in list_of_sent: # for each review/sentence\n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        if word in w2v_words:\n",
    "            vec = w2v_model.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt_words += 1\n",
    "    if cnt_words != 0:\n",
    "        sent_vec /= cnt_words\n",
    "    sent_vectors.append(sent_vec)\n",
    "print(len(sent_vectors))\n",
    "#print(len(sent_vectors[0]))\n",
    "print(type(sent_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create design matrix X and target vector y\n",
    "X = np.array(sent_vectors[::]) # end index is exclusive\n",
    "y = np.array(final['Score']) # showing you two ways of indexing a pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 50)\n",
      "(18000, 50)\n",
      "(42000,)\n",
      "(18000,)\n"
     ]
    }
   ],
   "source": [
    "X_train_nstd = X[0:42000:1]\n",
    "X_test_nstd = X[42000:60000:1]\n",
    "\n",
    "y_train_nstd = y[0:42000:1]\n",
    "y_test_nstd =y[42000:60000:1]\n",
    "\n",
    "print(X_train_nstd.shape)\n",
    "print(X_test_nstd.shape)\n",
    "print(y_train_nstd.shape)\n",
    "print(y_test_nstd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Standardization of the tfidf non-standard vector\n",
    "std_scal = StandardScaler(with_mean=False)\n",
    "std_scal.fit(X_train_nstd)\n",
    "train_avgw2v = std_scal.transform(X_train_nstd)\n",
    "test_avgw2v = std_scal.transform(X_test_nstd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=10000, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "Best score:  0.951193222202625\n",
      "0.9430497513955404\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_l1_avgw2v.pkl']"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using GridSearchCV with L1 Regularizer\n",
    "tuned_parameters = [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4]}]\n",
    "model_l1_avgw2v = GridSearchCV(LogisticRegression(penalty='l1'), tuned_parameters, scoring = 'f1', cv=5)\n",
    "model_l1_avgw2v.fit(train_avgw2v, y_train)\n",
    "\n",
    "GS_OPTIMAL_clf_l1_avgw2v = model_l1_avgw2v.best_estimator_\n",
    "print(GS_OPTIMAL_clf_l1_avgw2v)\n",
    "best_score_model_l1_avgw2v = model_l1_avgw2v.best_score_\n",
    "print(\"\\nBest score: \",best_score_model_l1_avgw2v)\n",
    "test_score_l1_avgw2v = model_l1_avgw2v.score(test_avgw2v, y_test)\n",
    "print(test_score_l1_avgw2v)\n",
    "\n",
    "#Writing data\n",
    "fileObject = open(\"./GS_OPTIMAL_clf_l1_avgw2v.pkl\",'wb')\n",
    "pickle.dump(GS_OPTIMAL_clf_l1_avgw2v,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "# open the file for writing an array to fileto be save on disk from X_test data\n",
    "fileObject = open(\"./best_score_model_l1_avgw2v.pkl\",'wb')\n",
    "pickle.dump(best_score_model_l1_avgw2v,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "# open the file for writing an array to fileto be save on disk from X_test data\n",
    "fileObject = open(\"./test_score_l1_avgw2v.pkl\",'wb')\n",
    "pickle.dump(test_score_l1_avgw2v,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "joblib.dump(model_l1_avgw2v,\"model_l1_avgw2v.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=10000, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.951193222202625\n",
      "0.9430497513955404\n",
      "GridSearchCV(cv=5, error_score='raise',\n",
      "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid=[{'C': [0.0001, 0.01, 1, 100, 10000]}],\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring='f1', verbose=0)\n"
     ]
    }
   ],
   "source": [
    "model_l1_avgw2v = joblib.load(\"model_l1_avgw2v.pkl\")\n",
    "\n",
    "fileObject = open(\"./GS_OPTIMAL_clf_l1_avgw2v.pkl\",'rb') # we open the file for reading \n",
    "GS_OPTIMAL_clf_l1_avgw2v = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "fileObject = open(\"./best_score_model_l1_avgw2v.pkl\",'rb') # we open the file for reading \n",
    "best_score_model_l1_avgw2v = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "fileObject = open(\"./test_score_l1_avgw2v.pkl\",'rb') # we open the file for reading \n",
    "test_score_l1_avgw2v = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "print(GS_OPTIMAL_clf_l1_avgw2v)\n",
    "print(best_score_model_l1_avgw2v)\n",
    "print(test_score_l1_avgw2v)\n",
    "print(model_l1_avgw2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for alphas:\n",
      "[mean: 0.93630, std: 0.00075, params: {'C': 0.0001}, mean: 0.95011, std: 0.00076, params: {'C': 0.01}, mean: 0.95117, std: 0.00089, params: {'C': 1}, mean: 0.95114, std: 0.00079, params: {'C': 100}, mean: 0.95119, std: 0.00083, params: {'C': 10000}]\n",
      "Best estimator:\n",
      "LogisticRegression(C=10000, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Best score:\n",
      "0.951193222202625\n",
      "Best parameters:\n",
      "{'C': 10000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AbhiShek\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "    print(\"Scores for alphas:\")\n",
    "    print(model_l1_avgw2v.grid_scores_)\n",
    "    print(\"Best estimator:\")\n",
    "    print(model_l1_avgw2v.best_estimator_)\n",
    "    print(\"Best score:\")\n",
    "    print(model_l1_avgw2v.best_score_)\n",
    "    print(\"Best parameters:\")\n",
    "    print(model_l1_avgw2v.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "Best score:  0.9512152832878302\n",
      "0.9428162756018139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_l2_avgw2v.pkl']"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using GridSearchCV with L2 Regularizer\n",
    "tuned_parameters = [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4]}]\n",
    "model_l2_avgw2v = GridSearchCV(LogisticRegression(penalty='l2'), tuned_parameters, scoring = 'f1', cv=5)\n",
    "model_l2_avgw2v.fit(train_avgw2v, y_train)\n",
    "\n",
    "GS_OPTIMAL_clf_l2_avgw2v = model_l2_avgw2v.best_estimator_\n",
    "print(GS_OPTIMAL_clf_l2_avgw2v)\n",
    "\n",
    "best_score_l2_avgw2v = model_l2_avgw2v.best_score_\n",
    "print(\"\\nBest score: \",best_score_l2_avgw2v)\n",
    "test_score_l2_avgw2v = model_l2_avgw2v.score(test_avgw2v, y_test)\n",
    "print(test_score_l2_avgw2v)\n",
    "\n",
    "\n",
    "#Writing data\n",
    "fileObject = open(\"./GS_OPTIMAL_clf_l2_avgw2v.pkl\",'wb')\n",
    "pickle.dump(GS_OPTIMAL_clf_l2_avgw2v,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "# open the file for writing an array to fileto be save on disk from X_test data\n",
    "fileObject = open(\"./best_score_l2_avgw2v.pkl\",'wb')\n",
    "pickle.dump(best_score_l2_avgw2v,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "# open the file for writing an array to fileto be save on disk from X_test data\n",
    "fileObject = open(\"./test_score_l2_avgw2v.pkl\",'wb')\n",
    "pickle.dump(test_score_l2_avgw2v,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "joblib.dump(model_l2_avgw2v,\"model_l2_avgw2v.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.9512152832878302\n",
      "0.9428162756018139\n",
      "GridSearchCV(cv=5, error_score='raise',\n",
      "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid=[{'C': [0.0001, 0.01, 1, 100, 10000]}],\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring='f1', verbose=0)\n"
     ]
    }
   ],
   "source": [
    "model_l2_avgw2v = joblib.load(\"model_l2_avgw2v.pkl\")\n",
    "\n",
    "fileObject = open(\"./GS_OPTIMAL_clf_l2_avgw2v.pkl\",'rb') # we open the file for reading \n",
    "GS_OPTIMAL_clf_l2_avgw2v = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "fileObject = open(\"./best_score_l2_avgw2v.pkl\",'rb') # we open the file for reading \n",
    "best_score_l2_avgw2v = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "fileObject = open(\"./test_score_l2_avgw2v.pkl\",'rb') # we open the file for reading \n",
    "test_score_l2_avgw2v = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "print(GS_OPTIMAL_clf_l2_avgw2v)\n",
    "print(best_score_l2_avgw2v)\n",
    "print(test_score_l2_avgw2v)\n",
    "print(model_l2_avgw2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 [[ 6.98516932e-02 -1.75376265e-02  7.29592654e-01  2.55101350e-01\n",
      "   2.10392056e-01  0.00000000e+00  1.47063075e-01 -6.89877947e-02\n",
      "  -3.09280345e-01  1.84751934e-01 -5.65786826e-04  1.66184680e-01\n",
      "  -5.52520415e-01 -3.22191197e-02  0.00000000e+00  1.66029593e-01\n",
      "   4.21394040e-02 -2.52941418e-01  8.03197724e-02  2.71895196e-01\n",
      "   8.85422133e-02 -6.56343452e-02  4.22168426e-02  0.00000000e+00\n",
      "   0.00000000e+00  4.37951817e-01  5.41808579e-02 -1.09322279e-02\n",
      "  -1.47742760e-02  5.00737528e-01  0.00000000e+00  0.00000000e+00\n",
      "   6.44972917e-02  2.40154904e-01 -4.26238007e-01  5.62423153e-01\n",
      "  -7.14173349e-02  0.00000000e+00  1.59133104e-01  2.86625452e-01\n",
      "  -1.82744650e-01  0.00000000e+00  0.00000000e+00 -4.77508154e-01\n",
      "   6.99983461e-01 -5.49134982e-02 -2.54480896e-01  0.00000000e+00\n",
      "  -7.57504541e-02  5.78774249e-02]]\n"
     ]
    }
   ],
   "source": [
    "# More Sparsity (Fewer elements of W* being non-zero) by increasing Lambda (decreasing C) \n",
    "clf_c1_avgw2v = LogisticRegression(C=0.01, penalty='l1');\n",
    "clf_c1_avgw2v.fit(train_avgw2v, y_train);\n",
    "w_avgw2v = clf_c1_avgw2v.coef_\n",
    "print(np.count_nonzero(w_avgw2v), w_avgw2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "# More Sparsity (Fewer elements of W* being non-zero) by increasing Lambda (decreasing C) \n",
    "clf_c2_avgw2v = LogisticRegression(C=0.1, penalty='l1');\n",
    "clf_c2_avgw2v.fit(train_avgw2v, y_train);\n",
    "w_avgw2v = clf_c2_avgw2v.coef_\n",
    "print(np.count_nonzero(w_avgw2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "# More Sparsity (Fewer elements of W* being non-zero) by decreasing Lambda (increasing C) \n",
    "clf_c3_avgw2v = LogisticRegression(C=1, penalty='l1');\n",
    "clf_c3_avgw2v.fit(train_avgw2v, y_train);\n",
    "w_avgw2v = clf_c3_avgw2v.coef_\n",
    "print(np.count_nonzero(w_avgw2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "# More Sparsity (Fewer elements of W* being non-zero) by increasing Lambda (decreasing C) \n",
    "clf_c4_avgw2v = LogisticRegression(C=10, penalty='l1');\n",
    "clf_c4_avgw2v.fit(train_avgw2v, y_train);\n",
    "w_avgw2v = clf_c4_avgw2v.coef_\n",
    "print(np.count_nonzero(w_avgw2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "(1, 50)\n"
     ]
    }
   ],
   "source": [
    "# More Sparsity (Fewer elements of W* being non-zero) by increasing Lambda (decreasing C) \n",
    "clf_c5_avgw2v = LogisticRegression(C=100, penalty='l1');\n",
    "clf_c5_avgw2v.fit(train_avgw2v, y_train);\n",
    "w_avgw2v = clf_c5_avgw2v.coef_\n",
    "print(np.count_nonzero(w_avgw2v))\n",
    "print(np.shape(w_avgw2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "w:  [[ 6.97723263e-02 -1.62481494e-02  7.29203572e-01  2.55036264e-01\n",
      "   2.10491821e-01  1.00000000e-07  1.47084969e-01 -6.90965759e-02\n",
      "  -3.09184901e-01  1.84549089e-01 -5.87179379e-04  1.66430631e-01\n",
      "  -5.52430393e-01 -3.17011651e-02  1.00000000e-07  1.66005218e-01\n",
      "   4.24870071e-02 -2.52712497e-01  8.11346011e-02  2.71993720e-01\n",
      "   8.85462135e-02 -6.54917838e-02  4.26425917e-02  1.00000000e-07\n",
      "   1.00000000e-07  4.37358803e-01  5.42821133e-02 -1.07624277e-02\n",
      "  -1.46827992e-02  5.01007415e-01  1.00000000e-07  1.00000000e-07\n",
      "   6.45495848e-02  2.40418689e-01 -4.26611849e-01  5.62436824e-01\n",
      "  -7.11630133e-02  1.00000000e-07  1.59461786e-01  2.86855042e-01\n",
      "  -1.82845092e-01  1.00000000e-07  1.00000000e-07 -4.76998374e-01\n",
      "   7.00167664e-01 -5.44243859e-02 -2.54344027e-01  1.00000000e-07\n",
      "  -7.57513483e-02  5.75005556e-02]]\n",
      "w_1:  [[ 6.94018498e-02 -1.67001213e-02  7.28926089e-01  2.54966245e-01\n",
      "   2.10294663e-01  1.00000000e-07  1.47230369e-01 -6.90171417e-02\n",
      "  -3.08737782e-01  1.84445573e-01 -6.42103935e-04  1.65832761e-01\n",
      "  -5.52503103e-01 -3.13057348e-02  1.00000000e-07  1.66366063e-01\n",
      "   4.22758918e-02 -2.52831417e-01  8.13456084e-02  2.71914615e-01\n",
      "   8.86148865e-02 -6.52940206e-02  4.26214262e-02  1.00000000e-07\n",
      "   1.00000000e-07  4.37867748e-01  5.44317082e-02 -1.05514007e-02\n",
      "  -1.49627624e-02  5.01089230e-01  1.00000000e-07  1.00000000e-07\n",
      "   6.45388391e-02  2.40266603e-01 -4.26582631e-01  5.62306447e-01\n",
      "  -7.16477086e-02  1.00000000e-07  1.59155496e-01  2.86888371e-01\n",
      "  -1.82592037e-01  1.00000000e-07  1.00000000e-07 -4.77144524e-01\n",
      "   6.99625330e-01 -5.42614199e-02 -2.54260112e-01  1.00000000e-07\n",
      "  -7.53208263e-02  5.76363149e-02]]\n",
      "per_array:  [[5.30979183e-01 2.78168227e+00 3.80528934e-02 2.74543198e-02\n",
      "  9.36655079e-02 0.00000000e+00 9.88544833e-02 1.14961143e-01\n",
      "  1.44612162e-01 5.60914040e-02 9.35396535e+00 3.59230511e-01\n",
      "  1.31616873e-02 1.24736836e+00 0.00000000e+00 2.17369948e-01\n",
      "  4.96893705e-01 4.70573933e-02 2.60070668e-01 2.90834462e-02\n",
      "  7.75561984e-02 3.01966432e-01 4.96345197e-02 0.00000000e+00\n",
      "  0.00000000e+00 1.16367779e-01 2.75587671e-01 1.96077445e+00\n",
      "  1.90674268e+00 1.63300882e-02 0.00000000e+00 0.00000000e+00\n",
      "  1.66470814e-02 6.32589700e-02 6.84870977e-03 2.31807841e-02\n",
      "  6.81105644e-01 0.00000000e+00 1.92077742e-01 1.16187059e-02\n",
      "  1.38398881e-01 0.00000000e+00 0.00000000e+00 3.06395597e-02\n",
      "  7.74576575e-02 2.99435570e-01 3.29927259e-02 0.00000000e+00\n",
      "  5.68335688e-01 2.36100801e-01]]\n"
     ]
    }
   ],
   "source": [
    "#perturbation testing\n",
    "index = []\n",
    "\n",
    "clf_c1_avgw2v.fit(train_avgw2v, y_train)\n",
    "w_avgw2v=clf_c1_avgw2v.coef_+0.0000001\n",
    "#print(np.shape(w_avgw2v))\n",
    "print(\"w: \",w_avgw2v)\n",
    "\n",
    "loop6 = np.shape(train_avgw2v)\n",
    "\n",
    "for loop7 in range(1,loop6[0],1):\n",
    "    for loop8 in range(1,loop6[1],1):\n",
    "        train_avgw2v[loop7,loop8] += 0.001\n",
    "\n",
    "#train_avgw2v.data += 0.001\n",
    "clf_c1_avgw2v.fit(train_avgw2v, y_train)\n",
    "w_1_avgw2v=clf_c1_avgw2v.coef_+0.0000001\n",
    "#print(np.shape(w_1_avgw2v))\n",
    "print(\"w_1: \",w_1_avgw2v)\n",
    "\n",
    "per_array_avgw2v = np.abs((w_avgw2v-w_1_avgw2v)/w_avgw2v)*100\n",
    "print(\"per_array: \",per_array_avgw2v)\n",
    "#print(np.shape(per_array_avgw2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights =  0.0\n",
      "Weights =  0.0\n",
      "Weights =  0.005478967816758141\n",
      "Weights =  0.02122067331055677\n",
      "Weights =  0.036028826404350865\n",
      "Weights =  0.07035831377608062\n",
      "Weights =  0.11552379731928807\n",
      "Weights =  0.2229892035533302\n",
      "Weights =  0.3134192475483672\n",
      "Weights =  0.737731915585059\n",
      "Weights =  9.353965345650037\n",
      "**************************\n"
     ]
    }
   ],
   "source": [
    "#between 1st-100th percentile\n",
    "for i in range(0,101,10):\n",
    "    Weights_avgw2v = np.percentile(per_array_avgw2v, i)\n",
    "    print(\"Weights = \",Weights_avgw2v)\n",
    "print(\"**************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights =  0.737731915585059\n",
      "Weights =  1.0152006481460711\n",
      "Weights =  1.3001183083054997\n",
      "Weights =  1.6232117224068074\n",
      "Weights =  1.9099845839152287\n",
      "Weights =  1.936460151841278\n",
      "Weights =  1.9936107616722316\n",
      "Weights =  2.3958555929333674\n",
      "Weights =  2.9131279293731396\n",
      "Weights =  6.133546637511588\n",
      "Weights =  9.353965345650037\n",
      "**************************\n"
     ]
    }
   ],
   "source": [
    "#between 90th-100th percentile\n",
    "for i in range(90,101,1):\n",
    "    Weights_avgw2v = np.percentile(per_array_avgw2v, i)\n",
    "    print(\"Weights = \",Weights_avgw2v)\n",
    "print(\"**************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights =  6.133546637511588\n",
      "Weights =  6.4555885083254285\n",
      "Weights =  6.777630379139269\n",
      "Weights =  7.099672249953109\n",
      "Weights =  7.421714120766903\n",
      "Weights =  7.743755991580695\n",
      "Weights =  8.065797862394536\n",
      "Weights =  8.387839733208377\n",
      "Weights =  8.709881604022216\n",
      "Weights =  9.031923474836011\n",
      "Weights =  9.35396534564985\n",
      "**************************\n"
     ]
    }
   ],
   "source": [
    "#between 99th-100th percentile\n",
    "k=99\n",
    "for i in range(1,12,1):\n",
    "    Weights_3 = np.percentile(per_array_avgw2v, k)\n",
    "    print(\"Weights = \",Weights_3)   \n",
    "    k+=0.1\n",
    "print(\"**************************\")\n",
    "\n",
    "#No abrupt chnages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l1\n",
      "Best C: 0.9183088549193021\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['clf_rscv_avgw2v.pkl']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create logistic regression\n",
    "logistic_avgw2v = LogisticRegression()\n",
    "\n",
    "# Create regularization penalty space\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create regularization hyperparameter distribution using uniform distribution\n",
    "C = uniform(loc=0, scale=4)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "# Create randomized search 5-fold cross validation and 100 iterations\n",
    "clf_rscv_avgw2v = RandomizedSearchCV(logistic_avgw2v, hyperparameters, random_state=1, cv=5)\n",
    "\n",
    "# Fit randomized search\n",
    "best_model_avgw2v = clf_rscv_avgw2v.fit(train_avgw2v, y_train)\n",
    "\n",
    "# View best hyperparameters\n",
    "best_penalty_avgw2v = best_model_avgw2v.best_estimator_.get_params()['penalty']\n",
    "print('Best Penalty:',best_penalty_avgw2v )\n",
    "best_c_avgw2v = best_model_avgw2v.best_estimator_.get_params()['C']\n",
    "print('Best C:',best_c_avgw2v)\n",
    "\n",
    "# Predict target vector\n",
    "predict_test_avgw2v = best_model_avgw2v.predict(test_avgw2v)\n",
    "\n",
    "#Writing data\n",
    "fileObject = open(\"./best_penalty_avgw2v.pkl\",'wb')\n",
    "pickle.dump(best_penalty_avgw2v,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "# open the file for writing an array to fileto be save on disk from X_test data\n",
    "fileObject = open(\"./best_c_avgw2v.pkl\",'wb')\n",
    "pickle.dump(best_c_avgw2v,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "# open the file for writing an array to fileto be save on disk from X_test data\n",
    "fileObject = open(\"./predict_test_avgw2v.pkl\",'wb')\n",
    "pickle.dump(predict_test_avgw2v,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "joblib.dump(clf_rscv_avgw2v,\"clf_rscv_avgw2v.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1\n",
      "0.9183088549193021\n",
      "[1 1 1 ... 1 1 1]\n",
      "RandomizedSearchCV(cv=5, error_score='raise',\n",
      "          estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
      "          param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x000002651DFBC208>, 'penalty': ['l1', 'l2']},\n",
      "          pre_dispatch='2*n_jobs', random_state=1, refit=True,\n",
      "          return_train_score='warn', scoring=None, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "clf_rscv_avgw2v = joblib.load(\"clf_rscv_avgw2v.pkl\")\n",
    "\n",
    "fileObject = open(\"./best_penalty.pkl\",'rb') # we open the file for reading \n",
    "best_penalty = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "fileObject = open(\"./best_c.pkl\",'rb') # we open the file for reading \n",
    "best_c = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "fileObject = open(\"./predict_test.pkl\",'rb') # we open the file for reading \n",
    "predict_test = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "print(best_penalty_avgw2v)\n",
    "print(best_c_avgw2v)\n",
    "print(predict_test_avgw2v)\n",
    "print(clf_rscv_avgw2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf-W-w2v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileObject = open(\"./final_to_file2.pkl\",'rb') # we open the file for reading \n",
    "final = pickle.load(fileObject) # load the object from the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n",
      "witti littl book make son laugh loud recit car drive along alway sing refrain hes learn whale india droop love new word book introduc silli classic book will bet son still abl recit memori colleg\n",
      "*****************************************************************\n",
      "['witti', 'littl', 'book', 'make', 'son', 'laugh', 'loud', 'recit', 'car', 'drive', 'along', 'alway', 'sing', 'refrain', 'hes', 'learn', 'whale', 'india', 'droop', 'love', 'new', 'word', 'book', 'introduc', 'silli', 'classic', 'book', 'will', 'bet', 'son', 'still', 'abl', 'recit', 'memori', 'colleg']\n"
     ]
    }
   ],
   "source": [
    "#w2v\n",
    "# Train your own Word2Vec model using your own text corpus\n",
    "i=0\n",
    "list_of_sent=[]\n",
    "for sent in final['CleanedText'].values:\n",
    "    list_of_sent.append(sent.split())\n",
    "    \n",
    "print(type(list_of_sent))\n",
    "print(final['CleanedText'].values[0])\n",
    "print(\"*****************************************************************\")\n",
    "print(list_of_sent[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model=Word2Vec(list_of_sent,min_count=5,size=50, workers=4)\n",
    "w2v_words = list(w2v_model.wv.vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S = [\"abc def pqr\", \"def def def abc\", \"pqr pqr def\"]\n",
    "model = TfidfVectorizer()\n",
    "tf_idf_matrix = model.fit_transform(final['CleanedText'].values)\n",
    "# we are converting a dictionary with word as a key, and the idf as a value\n",
    "dictionary = dict(zip(model.get_feature_names(), list(model.idf_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TF-IDF weighted Word2Vec\n",
    "tfidf_feat = model.get_feature_names() # tfidf words/col-names\n",
    "# final_tf_idf is the sparse matrix with row= sentence, col=word and cell_val = tfidf\n",
    "\n",
    "tfidf_sent_vectors = []; # the tfidf-w2v for each sentence/review is stored in this list\n",
    "row=0;\n",
    "for sent in (list_of_sent): # for each review/sentence \n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    weight_sum =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        if word in w2v_words:\n",
    "            vec = w2v_model.wv[word]\n",
    "#             tf_idf = tf_idf_matrix[row, tfidf_feat.index(word)]\n",
    "            # to reduce the computation we are \n",
    "            # dictionary[word] = idf value of word in whole courpus\n",
    "            # sent.count(word) = tf valeus of word in this review\n",
    "            tf_idf = dictionary[word]*(sent.count(word)/len(sent))\n",
    "            sent_vec += (vec * tf_idf)\n",
    "            weight_sum += tf_idf\n",
    "    if weight_sum != 0:\n",
    "        sent_vec /= weight_sum\n",
    "    tfidf_sent_vectors.append(sent_vec)\n",
    "    row += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "(60000, 50)\n",
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(len(tfidf_sent_vectors))\n",
    "print(np.shape(tfidf_sent_vectors))\n",
    "print(type(tfidf_sent_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create design matrix X and target vector y\n",
    "X = np.array(sent_vectors[::]) # end index is exclusive\n",
    "y = np.array(final['Score']) # showing you two ways of indexing a pandas df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(42000, 50)\n",
      "(18000, 50)\n",
      "(42000,)\n",
      "(18000,)\n"
     ]
    }
   ],
   "source": [
    "X_train_nstd = X[0:42000:1]\n",
    "X_test_nstd = X[42000:60000:1]\n",
    "\n",
    "y_train_nstd = y[0:42000:1]\n",
    "y_test_nstd =y[42000:60000:1]\n",
    "\n",
    "print(X_train_nstd.shape)\n",
    "print(X_test_nstd.shape)\n",
    "print(y_train_nstd.shape)\n",
    "print(y_test_nstd.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Column Standardization of the tfidf non-standard vector\n",
    "std_scal = StandardScaler(with_mean=False)\n",
    "std_scal.fit(X_train_nstd)\n",
    "train_tfidfww2v = std_scal.transform(X_train_nstd)\n",
    "test_tfidfww2v = std_scal.transform(X_test_nstd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=10000, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "Best score:  0.9511945209425645\n",
      "0.9430532255604698\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_l1_tfidfww2v.pkl']"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using GridSearchCV with L1 Regularizer\n",
    "tuned_parameters = [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4]}]\n",
    "model_l1_tfidfww2v = GridSearchCV(LogisticRegression(penalty='l1'), tuned_parameters, scoring = 'f1', cv=5)\n",
    "model_l1_tfidfww2v.fit(train_tfidfww2v, y_train)\n",
    "\n",
    "GS_OPTIMAL_clf_l1_tfidfww2v = model_l1_tfidfww2v.best_estimator_\n",
    "print(GS_OPTIMAL_clf_l1_tfidfww2v)\n",
    "best_score_model_l1_tfidfww2v = model_l1_tfidfww2v.best_score_\n",
    "print(\"\\nBest score: \",best_score_model_l1_tfidfww2v)\n",
    "test_score_l1_tfidfww2v = model_l1_tfidfww2v.score(test_tfidfww2v, y_test)\n",
    "print(test_score_l1_tfidfww2v)\n",
    "\n",
    "#Writing data\n",
    "fileObject = open(\"./GS_OPTIMAL_clf_l1_tfidfww2v.pkl\",'wb')\n",
    "pickle.dump(GS_OPTIMAL_clf_l1_tfidfww2v,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "# open the file for writing an array to fileto be save on disk from X_test data\n",
    "fileObject = open(\"./best_score_model_l1_tfidfww2v.pkl\",'wb')\n",
    "pickle.dump(best_score_model_l1_tfidfww2v,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "# open the file for writing an array to fileto be save on disk from X_test data\n",
    "fileObject = open(\"./test_score_l1_tfidfww2v.pkl\",'wb')\n",
    "pickle.dump(test_score_l1_tfidfww2v,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "joblib.dump(model_l1_tfidfww2v,\"model_l1_tfidfww2v.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=10000, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.9511945209425645\n",
      "0.9430532255604698\n",
      "GridSearchCV(cv=5, error_score='raise',\n",
      "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid=[{'C': [0.0001, 0.01, 1, 100, 10000]}],\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring='f1', verbose=0)\n"
     ]
    }
   ],
   "source": [
    "model_l1_tfidfww2v = joblib.load(\"model_l1_tfidfww2v.pkl\")\n",
    "\n",
    "fileObject = open(\"./GS_OPTIMAL_clf_l1_tfidfww2v.pkl\",'rb') # we open the file for reading \n",
    "GS_OPTIMAL_clf_l1_tfidfww2v = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "fileObject = open(\"./best_score_model_l1_tfidfww2v.pkl\",'rb') # we open the file for reading \n",
    "best_score_model_l1_tfidfww2v = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "fileObject = open(\"./test_score_l1_tfidfww2v.pkl\",'rb') # we open the file for reading \n",
    "test_score_l1_tfidfww2v = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "print(GS_OPTIMAL_clf_l1_tfidfww2v)\n",
    "print(best_score_model_l1_tfidfww2v)\n",
    "print(test_score_l1_tfidfww2v)\n",
    "print(model_l1_tfidfww2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores for alphas:\n",
      "[mean: 0.93630, std: 0.00075, params: {'C': 0.0001}, mean: 0.95006, std: 0.00079, params: {'C': 0.01}, mean: 0.95116, std: 0.00090, params: {'C': 1}, mean: 0.95115, std: 0.00087, params: {'C': 100}, mean: 0.95119, std: 0.00087, params: {'C': 10000}]\n",
      "Best estimator:\n",
      "LogisticRegression(C=10000, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l1', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "Best score:\n",
      "0.9511945209425645\n",
      "Best parameters:\n",
      "{'C': 10000}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\AbhiShek\\Anaconda3\\lib\\site-packages\\sklearn\\model_selection\\_search.py:761: DeprecationWarning: The grid_scores_ attribute was deprecated in version 0.18 in favor of the more elaborate cv_results_ attribute. The grid_scores_ attribute will not be available from 0.20\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "    print(\"Scores for alphas:\")\n",
    "    print(model_l1_tfidfww2v.grid_scores_)\n",
    "    print(\"Best estimator:\")\n",
    "    print(model_l1_tfidfww2v.best_estimator_)\n",
    "    print(\"Best score:\")\n",
    "    print(model_l1_tfidfww2v.best_score_)\n",
    "    print(\"Best parameters:\")\n",
    "    print(model_l1_tfidfww2v.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "\n",
      "Best score:  0.9512152832878302\n",
      "0.9428162756018139\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['model_l2_tfidfww2v.pkl']"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Using GridSearchCV with L2 Regularizer\n",
    "tuned_parameters = [{'C': [10**-4, 10**-2, 10**0, 10**2, 10**4]}]\n",
    "model_l2_tfidfww2v = GridSearchCV(LogisticRegression(penalty='l2'), tuned_parameters, scoring = 'f1', cv=5)\n",
    "model_l2_tfidfww2v.fit(train_tfidfww2v, y_train)\n",
    "\n",
    "GS_OPTIMAL_clf_l2_tfidfww2v = model_l2_tfidfww2v.best_estimator_\n",
    "print(GS_OPTIMAL_clf_l2_tfidfww2v)\n",
    "\n",
    "best_score_l2_tfidfww2v = model_l2_tfidfww2v.best_score_\n",
    "print(\"\\nBest score: \",best_score_l2_tfidfww2v)\n",
    "test_score_l2_tfidfww2v = model_l2_tfidfww2v.score(test_tfidfww2v, y_test)\n",
    "print(test_score_l2_tfidfww2v)\n",
    "\n",
    "\n",
    "#Writing data\n",
    "fileObject = open(\"./GS_OPTIMAL_clf_l2_tfidfww2v.pkl\",'wb')\n",
    "pickle.dump(GS_OPTIMAL_clf_l2_tfidfww2v,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "# open the file for writing an array to fileto be save on disk from X_test data\n",
    "fileObject = open(\"./best_score_l2_tfidfww2v.pkl\",'wb')\n",
    "pickle.dump(best_score_l2_tfidfww2v,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "# open the file for writing an array to fileto be save on disk from X_test data\n",
    "fileObject = open(\"./test_score_l2_tfidfww2v.pkl\",'wb')\n",
    "pickle.dump(test_score_l2_tfidfww2v,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "joblib.dump(model_l2_tfidfww2v,\"model_l2_tfidfww2v.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression(C=0.01, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False)\n",
      "0.9512152832878302\n",
      "0.9428162756018139\n",
      "GridSearchCV(cv=5, error_score='raise',\n",
      "       estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "       fit_params=None, iid=True, n_jobs=1,\n",
      "       param_grid=[{'C': [0.0001, 0.01, 1, 100, 10000]}],\n",
      "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
      "       scoring='f1', verbose=0)\n"
     ]
    }
   ],
   "source": [
    "model_l2_tfidfww2v = joblib.load(\"model_l2_tfidfww2v.pkl\")\n",
    "\n",
    "fileObject = open(\"./GS_OPTIMAL_clf_l2_tfidfww2v.pkl\",'rb') # we open the file for reading \n",
    "GS_OPTIMAL_clf_l2_tfidfww2v = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "fileObject = open(\"./best_score_l2_tfidfww2v.pkl\",'rb') # we open the file for reading \n",
    "best_score_l2_tfidfww2v = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "fileObject = open(\"./test_score_l2_tfidfww2v.pkl\",'rb') # we open the file for reading \n",
    "test_score_l2_tfidfww2v = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "print(GS_OPTIMAL_clf_l2_tfidfww2v)\n",
    "print(best_score_l2_tfidfww2v)\n",
    "print(test_score_l2_tfidfww2v)\n",
    "print(model_l2_tfidfww2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40 [[ 6.93794145e-02 -1.73492025e-02  7.28943019e-01  2.55132574e-01\n",
      "   2.09901870e-01  0.00000000e+00  1.46763413e-01 -6.93507855e-02\n",
      "  -3.09706229e-01  1.84616079e-01 -6.30689661e-04  1.66091419e-01\n",
      "  -5.52489566e-01 -3.21086184e-02  0.00000000e+00  1.66002546e-01\n",
      "   4.23860170e-02 -2.53232469e-01  8.08049484e-02  2.72283439e-01\n",
      "   8.86037163e-02 -6.60818803e-02  4.25747691e-02  0.00000000e+00\n",
      "   0.00000000e+00  4.36667743e-01  5.41086919e-02 -1.09877426e-02\n",
      "  -1.49720287e-02  5.00919688e-01  0.00000000e+00  0.00000000e+00\n",
      "   6.46153761e-02  2.40456495e-01 -4.26418006e-01  5.62057391e-01\n",
      "  -7.12039084e-02  0.00000000e+00  1.59255535e-01  2.86914651e-01\n",
      "  -1.83090537e-01  0.00000000e+00  0.00000000e+00 -4.77443924e-01\n",
      "   7.00013832e-01 -5.46056966e-02 -2.54629268e-01  0.00000000e+00\n",
      "  -7.64290523e-02  5.80087623e-02]]\n"
     ]
    }
   ],
   "source": [
    "# More Sparsity (Fewer elements of W* being non-zero) by increasing Lambda (decreasing C) \n",
    "clf_c1_tfidfww2v = LogisticRegression(C=0.01, penalty='l1');\n",
    "clf_c1_tfidfww2v.fit(train_tfidfww2v, y_train);\n",
    "w_tfidfww2v = clf_c1_tfidfww2v.coef_\n",
    "print(np.count_nonzero(w_tfidfww2v), w_tfidfww2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "48\n"
     ]
    }
   ],
   "source": [
    "# More Sparsity (Fewer elements of W* being non-zero) by increasing Lambda (decreasing C) \n",
    "clf_c2_tfidfww2v = LogisticRegression(C=0.1, penalty='l1');\n",
    "clf_c2_tfidfww2v.fit(train_tfidfww2v, y_train);\n",
    "w_tfidfww2v = clf_c2_tfidfww2v.coef_\n",
    "print(np.count_nonzero(w_tfidfww2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "# More Sparsity (Fewer elements of W* being non-zero) by decreasing Lambda (increasing C) \n",
    "clf_c3_tfidfww2v = LogisticRegression(C=1, penalty='l1');\n",
    "clf_c3_tfidfww2v.fit(train_tfidfww2v, y_train);\n",
    "w_tfidfww2v = clf_c3_tfidfww2v.coef_\n",
    "print(np.count_nonzero(w_tfidfww2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "# More Sparsity (Fewer elements of W* being non-zero) by increasing Lambda (decreasing C) \n",
    "clf_c4_tfidfww2v = LogisticRegression(C=10, penalty='l1');\n",
    "clf_c4_tfidfww2v.fit(train_tfidfww2v, y_train);\n",
    "w_tfidfww2v = clf_c4_tfidfww2v.coef_\n",
    "print(np.count_nonzero(w_tfidfww2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n",
      "(1, 50)\n"
     ]
    }
   ],
   "source": [
    "# More Sparsity (Fewer elements of W* being non-zero) by increasing Lambda (decreasing C) \n",
    "clf_c5_tfidfww2v = LogisticRegression(C=100, penalty='l1');\n",
    "clf_c5_tfidfww2v.fit(train_tfidfww2v, y_train);\n",
    "w_tfidfww2v = clf_c5_tfidfww2v.coef_\n",
    "print(np.count_nonzero(w_tfidfww2v))\n",
    "print(np.shape(w_tfidfww2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1, 50)\n",
      "w:  [[ 6.93841162e-02 -1.75219511e-02  7.29012364e-01  2.55046877e-01\n",
      "   2.10196350e-01  1.00000000e-07  1.47150673e-01 -6.92345133e-02\n",
      "  -3.09702337e-01  1.84726613e-01 -6.31923614e-04  1.65994761e-01\n",
      "  -5.52373019e-01 -3.22562695e-02  1.00000000e-07  1.66169004e-01\n",
      "   4.20675291e-02 -2.53614782e-01  8.02750689e-02  2.72308659e-01\n",
      "   8.81918090e-02 -6.57760672e-02  4.22928492e-02  1.00000000e-07\n",
      "   1.00000000e-07  4.37054975e-01  5.38621594e-02 -1.10032359e-02\n",
      "  -1.51373895e-02  5.00821609e-01  1.00000000e-07  1.00000000e-07\n",
      "   6.43265243e-02  2.40324697e-01 -4.26136320e-01  5.61957845e-01\n",
      "  -7.16834923e-02  1.00000000e-07  1.59202317e-01  2.87171240e-01\n",
      "  -1.82982446e-01  1.00000000e-07  1.00000000e-07 -4.77407559e-01\n",
      "   6.99653039e-01 -5.49652577e-02 -2.54529581e-01  1.00000000e-07\n",
      "  -7.64389059e-02  5.81360681e-02]]\n",
      "(1, 50)\n",
      "w_1:  [[ 6.96362789e-02 -1.63896846e-02  7.29398931e-01  2.55057764e-01\n",
      "   2.10307305e-01  1.00000000e-07  1.46906016e-01 -6.89805845e-02\n",
      "  -3.09177183e-01  1.84508927e-01 -6.15306544e-04  1.66257423e-01\n",
      "  -5.52532524e-01 -3.18834332e-02  1.00000000e-07  1.65999787e-01\n",
      "   4.25068945e-02 -2.52912522e-01  8.12291535e-02  2.71935069e-01\n",
      "   8.86308791e-02 -6.57248516e-02  4.27226556e-02  1.00000000e-07\n",
      "   1.00000000e-07  4.37039460e-01  5.43304253e-02 -1.07483601e-02\n",
      "  -1.47384670e-02  5.01045085e-01  1.00000000e-07  1.00000000e-07\n",
      "   6.45517457e-02  2.40510911e-01 -4.26519131e-01  5.62351571e-01\n",
      "  -7.11169460e-02  1.00000000e-07  1.59384300e-01  2.86907594e-01\n",
      "  -1.83046824e-01  1.00000000e-07  1.00000000e-07 -4.77111942e-01\n",
      "   7.00111452e-01 -5.44333218e-02 -2.54289785e-01  1.00000000e-07\n",
      "  -7.58409398e-02  5.74970568e-02]]\n",
      "per_array:  [[3.63430017e-01 6.46198865e+00 5.30261226e-02 4.26864617e-03\n",
      "  5.27866384e-02 0.00000000e+00 1.66262812e-01 3.66766113e-01\n",
      "  1.69567478e-01 1.17842238e-01 2.62960106e+00 1.58235692e-01\n",
      "  2.88761936e-02 1.15585698e+00 0.00000000e+00 1.01833935e-01\n",
      "  1.04442886e+00 2.76900259e-01 1.18851915e+00 1.37193884e-01\n",
      "  4.97858192e-01 7.78637128e-02 1.01626257e+00 0.00000000e+00\n",
      "  0.00000000e+00 3.54998666e-03 8.69378291e-01 2.31637131e+00\n",
      "  2.63534510e+00 4.46218843e-02 0.00000000e+00 0.00000000e+00\n",
      "  3.50122235e-01 7.74841963e-02 8.98330157e-02 7.00632862e-02\n",
      "  7.90344129e-01 0.00000000e+00 1.14309436e-01 9.18077268e-02\n",
      "  3.51823095e-02 0.00000000e+00 0.00000000e+00 6.19214315e-02\n",
      "  6.55201318e-02 9.67767640e-01 9.42115154e-02 0.00000000e+00\n",
      "  7.82279836e-01 1.09916507e+00]]\n",
      "(1, 50)\n"
     ]
    }
   ],
   "source": [
    "#perturbation testing\n",
    "index = []\n",
    "\n",
    "clf_c1_tfidfww2v.fit(train_tfidfww2v, y_train)\n",
    "w_tfidfww2v = clf_c1_tfidfww2v.coef_+0.0000001\n",
    "print(np.shape(w_tfidfww2v))\n",
    "print(\"w: \",w_tfidfww2v)\n",
    "\n",
    "loop6 = np.shape(train_tfidfww2v)\n",
    "\n",
    "for loop7 in range(1,loop6[0],1):\n",
    "    for loop8 in range(1,loop6[1],1):\n",
    "        train_tfidfww2v[loop7,loop8] += 0.001\n",
    "\n",
    "clf_c1_tfidfww2v.fit(train_tfidfww2v, y_train)\n",
    "w_1_tfidfww2v=clf_c1_tfidfww2v.coef_+0.0000001\n",
    "print(np.shape(w_1_tfidfww2v))\n",
    "print(\"w_1: \",w_1_tfidfww2v)\n",
    "\n",
    "per_array_tfidfww2v = np.abs((w_tfidfww2v - w_1_tfidfww2v)/w_tfidfww2v)*100\n",
    "print(\"per_array: \",per_array_tfidfww2v)\n",
    "print(np.shape(per_array_tfidfww2v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights =  0.0\n",
      "Weights =  0.0\n",
      "Weights =  0.002839989324653288\n",
      "Weights =  0.05033721217351338\n",
      "Weights =  0.07451583225277021\n",
      "Weights =  0.09802272519118367\n",
      "Weights =  0.16144653994680164\n",
      "Weights =  0.36443084572609147\n",
      "Weights =  0.8890561608963095\n",
      "Weights =  1.159123193004208\n",
      "Weights =  6.461988648219178\n",
      "**************************\n"
     ]
    }
   ],
   "source": [
    "#between 1st-100th percentile\n",
    "for i in range(0,101,10):\n",
    "    Weights = np.percentile(per_array_tfidfww2v, i)\n",
    "    print(\"Weights = \",Weights)\n",
    "print(\"**************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights =  1.159123193004208\n",
      "Weights =  1.175127659595327\n",
      "Weights =  1.27874732445494\n",
      "Weights =  1.831394880440543\n",
      "Weights =  2.335165092074807\n",
      "Weights =  2.4886476691911144\n",
      "Weights =  2.6298308180299297\n",
      "Weights =  2.63264539874696\n",
      "Weights =  2.7118779696103976\n",
      "Weights =  4.586933308914787\n",
      "Weights =  6.461988648219178\n",
      "**************************\n"
     ]
    }
   ],
   "source": [
    "#between 90th-100th percentile\n",
    "for i in range(90,101,1):\n",
    "    Weights = np.percentile(per_array_tfidfww2v, i)\n",
    "    print(\"Weights = \",Weights)\n",
    "print(\"**************************\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weights =  4.586933308914787\n",
      "Weights =  4.774438842845224\n",
      "Weights =  4.96194437677566\n",
      "Weights =  5.149449910706097\n",
      "Weights =  5.336955444636506\n",
      "Weights =  5.524460978566914\n",
      "Weights =  5.7119665124973515\n",
      "Weights =  5.899472046427787\n",
      "Weights =  6.086977580358224\n",
      "Weights =  6.274483114288633\n",
      "Weights =  6.4619886482190685\n",
      "**************************\n"
     ]
    }
   ],
   "source": [
    "#between 99th-100th percentile\n",
    "k=99\n",
    "for i in range(1,12,1):\n",
    "    Weights_3 = np.percentile(per_array_tfidfww2v, k)\n",
    "    print(\"Weights = \",Weights_3)   \n",
    "    k+=0.1\n",
    "print(\"**************************\")\n",
    "#No abrupt change in weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Penalty: l1\n",
      "Best C: 1.668088018810296\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['clf_rscv_tfidfww2v.pkl']"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create logistic regression\n",
    "logistic_tfidfww2v = LogisticRegression()\n",
    "\n",
    "# Create regularization penalty space\n",
    "penalty = ['l1', 'l2']\n",
    "\n",
    "# Create regularization hyperparameter distribution using uniform distribution\n",
    "C = uniform(loc=0, scale=4)\n",
    "\n",
    "# Create hyperparameter options\n",
    "hyperparameters = dict(C=C, penalty=penalty)\n",
    "\n",
    "# Create randomized search 5-fold cross validation and 100 iterations\n",
    "clf_rscv_tfidfww2v = RandomizedSearchCV(logistic_tfidfww2v, hyperparameters, random_state=1, cv=5)\n",
    "\n",
    "# Fit randomized search\n",
    "best_model_tfidfww2v = clf_rscv_tfidfww2v.fit(train_tfidfww2v, y_train)\n",
    "\n",
    "# View best hyperparameters\n",
    "best_penalty_tfidfww2v = best_model_tfidfww2v.best_estimator_.get_params()['penalty']\n",
    "print('Best Penalty:',best_penalty_tfidfww2v )\n",
    "best_c_tfidfww2v = best_model_tfidfww2v.best_estimator_.get_params()['C']\n",
    "print('Best C:',best_c_tfidfww2v)\n",
    "\n",
    "# Predict target vector\n",
    "predict_test_tfidfww2v = best_model_tfidfww2v.predict(test_tfidfww2v)\n",
    "\n",
    "#Writing data\n",
    "fileObject = open(\"./best_penalty_tfidfww2v.pkl\",'wb')\n",
    "pickle.dump(best_penalty_tfidfww2v,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "# open the file for writing an array to fileto be save on disk from X_test data\n",
    "fileObject = open(\"./best_c_tfidfww2v.pkl\",'wb')\n",
    "pickle.dump(best_c_tfidfww2v,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "# open the file for writing an array to fileto be save on disk from X_test data\n",
    "fileObject = open(\"./predict_test_tfidfww2v.pkl\",'wb')\n",
    "pickle.dump(predict_test_tfidfww2v,fileObject)   # this writes the object a to the file\n",
    "fileObject.close() # here we close the fileObject\n",
    "\n",
    "joblib.dump(clf_rscv_tfidfww2v,\"clf_rscv_tfidfww2v.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "l1\n",
      "1.668088018810296\n",
      "[1 1 1 ... 1 1 1]\n",
      "RandomizedSearchCV(cv=5, error_score='raise',\n",
      "          estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "          intercept_scaling=1, max_iter=100, multi_class='ovr', n_jobs=1,\n",
      "          penalty='l2', random_state=None, solver='liblinear', tol=0.0001,\n",
      "          verbose=0, warm_start=False),\n",
      "          fit_params=None, iid=True, n_iter=10, n_jobs=1,\n",
      "          param_distributions={'C': <scipy.stats._distn_infrastructure.rv_frozen object at 0x00000265197208D0>, 'penalty': ['l1', 'l2']},\n",
      "          pre_dispatch='2*n_jobs', random_state=1, refit=True,\n",
      "          return_train_score='warn', scoring=None, verbose=0)\n"
     ]
    }
   ],
   "source": [
    "clf_rscv_tfidfww2v = joblib.load(\"clf_rscv_tfidfww2v.pkl\")\n",
    "\n",
    "fileObject = open(\"./best_penalty_tfidfww2v.pkl\",'rb') # we open the file for reading \n",
    "best_penalty_tfidfww2v = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "fileObject = open(\"./best_c_tfidfww2v.pkl\",'rb') # we open the file for reading \n",
    "best_c_tfidfww2v = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "fileObject = open(\"./predict_test_tfidfww2v.pkl\",'rb') # we open the file for reading \n",
    "predict_test_tfidfww2v = pickle.load(fileObject) # load the object from the file\n",
    "\n",
    "print(best_penalty_tfidfww2v)\n",
    "print(best_c_tfidfww2v)\n",
    "print(predict_test_tfidfww2v)\n",
    "print(clf_rscv_tfidfww2v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
